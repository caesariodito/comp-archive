{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"./dataset/train_preprocessed_imputed_preprocessed.csv\")\n",
    "# df_target = df_train.pop(\"CO2 Emissions(g/km)\")\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(\"./dataset/test_preprocessed.csv\")\n",
    "# df_test.rename(\n",
    "#     columns={\n",
    "#         \"Fuel Consumption City\": \"Fuel Consumption City (L/100Km)\",\n",
    "#         \"Fuel Consumption Hwy\": \"Fuel Consumption Hwy (L/100Km)\",\n",
    "#         \"Fuel Consumption Comb\": \"Fuel Consumption Comb (L/100Km)\",\n",
    "#     },\n",
    "#     inplace=True,\n",
    "# )\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = pd.concat([df_train, df_test])\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fuelconsumption = df_all[\n",
    "#     [\n",
    "#         \"Fuel Consumption City (L/100Km)\",\n",
    "#         \"Fuel Consumption Hwy (L/100Km)\",\n",
    "#         \"Fuel Consumption Comb (L/100Km)\",\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# df_enginecylinders = df_all[\n",
    "#     # [\"Engine Size(L)\", \"Cylinders\", \"CO2 Emissions(g/km)\", \"Make\", \"Vehicle Class\"] # with category features\n",
    "#     [\"Engine Size(L)\", \"Cylinders\"]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "\n",
    "# imp = IterativeImputer(random_state=42)\n",
    "# imp.set_output(transform=\"pandas\")\n",
    "# imp.fit(df_fuelconsumption)\n",
    "# df_fuelconsumption_imputed = imp.transform(df_fuelconsumption)\n",
    "\n",
    "# imp = IterativeImputer(random_state=42)\n",
    "# imp.set_output(transform=\"pandas\")\n",
    "# imp.fit(df_enginecylinders)\n",
    "# df_enginecylinders_imputed = imp.transform(df_enginecylinders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add data to df_all_fix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # there were data < 0, so we need to replace it with 0\n",
    "\n",
    "# df_numerical_imputed = pd.concat(\n",
    "#     [df_fuelconsumption_imputed, df_enginecylinders_imputed], axis=1\n",
    "# )\n",
    "# df_numerical_imputed = df_numerical_imputed.clip(lower=0)\n",
    "\n",
    "# df_numerical_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix1 = df_all.drop(df_numerical_imputed.columns.tolist(), axis=1)\n",
    "# df_fix1 = pd.concat([df_fix1, df_numerical_imputed], axis=1)\n",
    "# df_fix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_categorical_imputed = df_fix1[\n",
    "#     [\n",
    "#         \"Make\",\n",
    "#         \"Vehicle Class\",\n",
    "#         \"Transmission\",\n",
    "#         \"Fuel Type\",\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#         \"Engine Size(L)\",\n",
    "#         \"Cylinders\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# for col in df_categorical_imputed.columns:\n",
    "#     if df_categorical_imputed[col].dtype == \"object\":\n",
    "#         df_categorical_imputed[col] = df_categorical_imputed[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import miceforest as mf\n",
    "\n",
    "# # might consider \"UserWarning: [Transmission,Fuel Type] have very rare categories, it is a good idea to group these, or set the min_data_in_leaf parameter to prevent lightgbm from outputting 0.0 probabilities.\"\n",
    "\n",
    "# kds = mf.ImputationKernel(\n",
    "#     df_categorical_imputed, save_all_iterations=True, random_state=42\n",
    "# )\n",
    "# kds.mice(10)\n",
    "# df_categorical_imputed = kds.complete_data()\n",
    "\n",
    "# df_categorical_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_categorical_impupted_fix = df_categorical_imputed.copy()\n",
    "# df_categorical_impupted_fix = df_categorical_impupted_fix.drop(\n",
    "#     [\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#         \"Engine Size(L)\",\n",
    "#         \"Cylinders\",\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix2 = df_fix1.drop(df_categorical_impupted_fix.columns.tolist(), axis=1)\n",
    "# df_fix2 = pd.concat([df_fix2, df_categorical_impupted_fix], axis=1)\n",
    "# df_fix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix3 = df_fix2.copy()\n",
    "# df_fix3.reset_index(drop=True, inplace=True)\n",
    "# df_fix3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix = df_fix3.iloc[:df_train.shape[0], :]\n",
    "# df_train_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_fix = df_fix3.iloc[df_train.shape[0] :, :]\n",
    "# df_test_fix.reset_index(drop=True, inplace=True)\n",
    "# df_test_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix = pd.concat([df_train_fix, df_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix.to_csv(\"./dataset/train_fix.csv\", index=False)\n",
    "# df_test_fix.to_csv(\"./dataset/test_fix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dython.nominal import associations\n",
    "\n",
    "# associations(df_train_fix)\n",
    "# associations(df_test_fix)\n",
    "# associations(df_fix3)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fix = pd.read_csv(\"./dataset/train_fix.csv\")\n",
    "df_test_fix = pd.read_csv(\"./dataset/test_fix.csv\")\n",
    "df_target = df_train_fix.pop(\"CO2 Emissions(g/km)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Value:\n",
    "- Fuel Consumption City (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Fuel Consumption Hwy (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Fuel Consumption Comb (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Engine Size(L) -> log, sqrt, boxcox, inverse\n",
    "- Cylinders -> log, sqrt, boxcox, inverse\n",
    "\n",
    "Categorical Value:\n",
    "- Make -> one-hot\n",
    "- Vehicle Class -> binary\n",
    "- Transmission -> binary \n",
    "- Fuel Type -> one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fix_preprocessed = df_train_fix.copy()\n",
    "df_test_fix_preprocessed = df_test_fix.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Fuel Consumption City (L/100Km)</th>\n",
       "      <th>Fuel Consumption Hwy (L/100Km)</th>\n",
       "      <th>Fuel Consumption Comb (L/100Km)</th>\n",
       "      <th>Engine Size(L)</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Make</th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Fuel Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.640000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>7.514791</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>FOLD</td>\n",
       "      <td>PICKUP TRUCK - STANDARD</td>\n",
       "      <td>A6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>28.840000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CHEVO</td>\n",
       "      <td>PICKUP TRUCK - STANDARD</td>\n",
       "      <td>A6</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>1.848477</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BMV</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>M6</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15.337423</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>15.590609</td>\n",
       "      <td>2.057097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>KIO</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.150000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BARUSU</td>\n",
       "      <td>MINICOMPACT</td>\n",
       "      <td>AS6</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137136</th>\n",
       "      <td>137137</td>\n",
       "      <td>33.710000</td>\n",
       "      <td>7.698229</td>\n",
       "      <td>22.026432</td>\n",
       "      <td>5.023977</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BMV</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>AS8</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137137</th>\n",
       "      <td>137138</td>\n",
       "      <td>6.489293</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>3.961175</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GONDA</td>\n",
       "      <td>STATION WAGON - SMALL</td>\n",
       "      <td>M6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137138</th>\n",
       "      <td>137139</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>5.412550</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NIRRAN</td>\n",
       "      <td>MID-SIZE</td>\n",
       "      <td>AV</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137139</th>\n",
       "      <td>137140</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>0.221408</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TOYOTI</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>AV</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137140</th>\n",
       "      <td>137141</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.098853</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BARUSU</td>\n",
       "      <td>MID-SIZE</td>\n",
       "      <td>AV6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137141 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Fuel Consumption City (L/100Km)  \\\n",
       "0            1                         8.640000   \n",
       "1            2                        27.270000   \n",
       "2            3                         1.700000   \n",
       "3            4                        15.337423   \n",
       "4            5                        20.150000   \n",
       "...        ...                              ...   \n",
       "137136  137137                        33.710000   \n",
       "137137  137138                         6.489293   \n",
       "137138  137139                         2.990000   \n",
       "137139  137140                        11.480000   \n",
       "137140  137141                         3.360000   \n",
       "\n",
       "        Fuel Consumption Hwy (L/100Km)  Fuel Consumption Comb (L/100Km)  \\\n",
       "0                             6.140000                         7.514791   \n",
       "1                            30.760000                        28.840000   \n",
       "2                             2.030000                         1.848477   \n",
       "3                            15.900000                        15.590609   \n",
       "4                             6.000000                        13.800000   \n",
       "...                                ...                              ...   \n",
       "137136                        7.698229                        22.026432   \n",
       "137137                        0.870000                         3.961175   \n",
       "137138                        8.380000                         5.412550   \n",
       "137139                        0.221408                         6.400000   \n",
       "137140                        2.800000                         3.098853   \n",
       "\n",
       "        Engine Size(L)  Cylinders    Make            Vehicle Class  \\\n",
       "0             3.500000        6.0    FOLD  PICKUP TRUCK - STANDARD   \n",
       "1             5.300000        8.0   CHEVO  PICKUP TRUCK - STANDARD   \n",
       "2             4.400000        6.0     BMV               SUBCOMPACT   \n",
       "3             2.057097        4.0     KIO              SUV - SMALL   \n",
       "4             3.000000        6.0  BARUSU              MINICOMPACT   \n",
       "...                ...        ...     ...                      ...   \n",
       "137136        5.023977        8.0     BMV               SUBCOMPACT   \n",
       "137137        1.500000        4.0   GONDA    STATION WAGON - SMALL   \n",
       "137138        1.800000        4.0  NIRRAN                 MID-SIZE   \n",
       "137139        1.800000        4.0  TOYOTI                  COMPACT   \n",
       "137140        2.500000        4.0  BARUSU                 MID-SIZE   \n",
       "\n",
       "       Transmission Fuel Type  \n",
       "0                A6         X  \n",
       "1                A6         E  \n",
       "2                M6         Z  \n",
       "3               AS6         X  \n",
       "4               AS6         Z  \n",
       "...             ...       ...  \n",
       "137136          AS8         Z  \n",
       "137137           M6         X  \n",
       "137138           AV         X  \n",
       "137139           AV         X  \n",
       "137140          AV6         X  \n",
       "\n",
       "[137141 rows x 10 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fix_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PowerTransformer <- MIGHT USE THIS\n",
    "\n",
    "column_to_transform = [\n",
    "    \"Fuel Consumption City (L/100Km)\",\n",
    "    \"Fuel Consumption Hwy (L/100Km)\",\n",
    "    \"Fuel Consumption Comb (L/100Km)\",\n",
    "    \"Engine Size(L)\",\n",
    "    \"Cylinders\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_log_\"+col] = np.log(df_train_fix_preprocessed[col] + 1)\n",
    "    df_test_fix_preprocessed[\"T_log_\"+col] = np.log(df_test_fix_preprocessed[col] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_sqrt_\"+col] = np.sqrt(df_train_fix_preprocessed[col])\n",
    "    df_test_fix_preprocessed[\"T_sqrt_\"+col] = np.sqrt(df_test_fix_preprocessed[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_boxcox_\"+col], _ = stats.boxcox(\n",
    "        df_train_fix_preprocessed[col] + 1\n",
    "    )\n",
    "    df_test_fix_preprocessed[\"T_boxcox_\"+col], _ = stats.boxcox(\n",
    "        df_test_fix_preprocessed[col] + 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_inverse_\"+col] = 1 / (df_train_fix_preprocessed[col] + 1)\n",
    "    df_test_fix_preprocessed[\"T_inverse_\"+col] = 1 / (df_test_fix_preprocessed[col] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "categorical_features_onehot = [\n",
    "    \"Make\",\n",
    "    \"Fuel Type\",\n",
    "]\n",
    "\n",
    "categorical_features_binary = [\n",
    "    \"Vehicle Class\",\n",
    "    \"Transmission\",\n",
    "]\n",
    "\n",
    "df_categorical_one_hot = df_train_fix_preprocessed[categorical_features_onehot].copy()\n",
    "df_categorical_binary = df_train_fix_preprocessed[categorical_features_binary].copy()\n",
    "\n",
    "encoder_onehot = OneHotEncoder(sparse_output=False)\n",
    "encoder_onehot.set_output(transform=\"pandas\")\n",
    "onehot_encoded_data = encoder_onehot.fit_transform(df_categorical_one_hot)\n",
    "# do the same with test data\n",
    "\n",
    "encoder_binary = BinaryEncoder(cols=categorical_features_binary)\n",
    "encoder_binary.set_output(transform=\"pandas\")\n",
    "df_binary = encoder_binary.fit_transform(df_categorical_binary)\n",
    "# do the same with test data\n",
    "\n",
    "\n",
    "onehot_encoded_data_cat = onehot_encoded_data.copy().astype(\"int64\").astype(\"category\")\n",
    "df_binary_cat = df_binary.copy().astype(\"int64\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_log = df_train_fix_preprocessed.filter(regex=\"T_log_\")\n",
    "df_train_sqrt = df_train_fix_preprocessed.filter(regex=\"T_sqrt_\")\n",
    "df_train_boxcox = df_train_fix_preprocessed.filter(regex=\"T_boxcox_\")\n",
    "df_train_inverse = df_train_fix_preprocessed.filter(regex=\"T_inverse_\")\n",
    "\n",
    "df_train_to_model_log = pd.concat(\n",
    "    [df_train_log, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")\n",
    "df_train_to_model_sqrt = pd.concat(\n",
    "    [df_train_sqrt, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")\n",
    "df_train_to_model_boxcox = pd.concat(\n",
    "    [df_train_boxcox, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")\n",
    "df_train_to_model_inverse = pd.concat(\n",
    "    [df_train_inverse, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_log_Fuel Consumption City (L/100Km)</th>\n",
       "      <th>T_log_Fuel Consumption Hwy (L/100Km)</th>\n",
       "      <th>T_log_Fuel Consumption Comb (L/100Km)</th>\n",
       "      <th>T_log_Engine Size(L)</th>\n",
       "      <th>T_log_Cylinders</th>\n",
       "      <th>Vehicle Class_0</th>\n",
       "      <th>Vehicle Class_1</th>\n",
       "      <th>Vehicle Class_2</th>\n",
       "      <th>Vehicle Class_3</th>\n",
       "      <th>Vehicle Class_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Make_MITSU</th>\n",
       "      <th>Make_NIRRAN</th>\n",
       "      <th>Make_RYUNDAI</th>\n",
       "      <th>Make_TOLVO</th>\n",
       "      <th>Make_TOYOTI</th>\n",
       "      <th>Fuel Type_D</th>\n",
       "      <th>Fuel Type_E</th>\n",
       "      <th>Fuel Type_N</th>\n",
       "      <th>Fuel Type_X</th>\n",
       "      <th>Fuel Type_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.265921</td>\n",
       "      <td>1.965713</td>\n",
       "      <td>2.141805</td>\n",
       "      <td>1.504077</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.341801</td>\n",
       "      <td>3.458208</td>\n",
       "      <td>3.395850</td>\n",
       "      <td>1.840550</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993252</td>\n",
       "      <td>1.108563</td>\n",
       "      <td>1.046785</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.793458</td>\n",
       "      <td>2.827314</td>\n",
       "      <td>2.808837</td>\n",
       "      <td>1.117466</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.051640</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.694627</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137136</th>\n",
       "      <td>3.547028</td>\n",
       "      <td>2.163119</td>\n",
       "      <td>3.136643</td>\n",
       "      <td>1.795748</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137137</th>\n",
       "      <td>2.013474</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>1.601643</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137138</th>\n",
       "      <td>1.383791</td>\n",
       "      <td>2.238580</td>\n",
       "      <td>1.858257</td>\n",
       "      <td>1.029619</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137139</th>\n",
       "      <td>2.524127</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>2.001480</td>\n",
       "      <td>1.029619</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137140</th>\n",
       "      <td>1.472472</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.410707</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137141 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        T_log_Fuel Consumption City (L/100Km)  \\\n",
       "0                                    2.265921   \n",
       "1                                    3.341801   \n",
       "2                                    0.993252   \n",
       "3                                    2.793458   \n",
       "4                                    3.051640   \n",
       "...                                       ...   \n",
       "137136                               3.547028   \n",
       "137137                               2.013474   \n",
       "137138                               1.383791   \n",
       "137139                               2.524127   \n",
       "137140                               1.472472   \n",
       "\n",
       "        T_log_Fuel Consumption Hwy (L/100Km)  \\\n",
       "0                                   1.965713   \n",
       "1                                   3.458208   \n",
       "2                                   1.108563   \n",
       "3                                   2.827314   \n",
       "4                                   1.945910   \n",
       "...                                      ...   \n",
       "137136                              2.163119   \n",
       "137137                              0.625938   \n",
       "137138                              2.238580   \n",
       "137139                              0.200004   \n",
       "137140                              1.335001   \n",
       "\n",
       "        T_log_Fuel Consumption Comb (L/100Km)  T_log_Engine Size(L)  \\\n",
       "0                                    2.141805              1.504077   \n",
       "1                                    3.395850              1.840550   \n",
       "2                                    1.046785              1.686399   \n",
       "3                                    2.808837              1.117466   \n",
       "4                                    2.694627              1.386294   \n",
       "...                                       ...                   ...   \n",
       "137136                               3.136643              1.795748   \n",
       "137137                               1.601643              0.916291   \n",
       "137138                               1.858257              1.029619   \n",
       "137139                               2.001480              1.029619   \n",
       "137140                               1.410707              1.252763   \n",
       "\n",
       "        T_log_Cylinders Vehicle Class_0 Vehicle Class_1 Vehicle Class_2  \\\n",
       "0              1.945910               0               0               0   \n",
       "1              2.197225               0               0               0   \n",
       "2              1.945910               0               0               0   \n",
       "3              1.609438               0               0               0   \n",
       "4              1.945910               0               0               1   \n",
       "...                 ...             ...             ...             ...   \n",
       "137136         2.197225               0               0               0   \n",
       "137137         1.609438               0               1               0   \n",
       "137138         1.609438               0               1               0   \n",
       "137139         1.609438               0               0               1   \n",
       "137140         1.609438               0               1               0   \n",
       "\n",
       "       Vehicle Class_3 Vehicle Class_4  ... Make_MITSU Make_NIRRAN  \\\n",
       "0                    0               1  ...          0           0   \n",
       "1                    0               1  ...          0           0   \n",
       "2                    1               0  ...          0           0   \n",
       "3                    1               1  ...          0           0   \n",
       "4                    0               0  ...          0           0   \n",
       "...                ...             ...  ...        ...         ...   \n",
       "137136               1               0  ...          0           0   \n",
       "137137               0               1  ...          0           0   \n",
       "137138               1               0  ...          0           1   \n",
       "137139               0               1  ...          0           0   \n",
       "137140               1               0  ...          0           0   \n",
       "\n",
       "       Make_RYUNDAI Make_TOLVO Make_TOYOTI Fuel Type_D Fuel Type_E  \\\n",
       "0                 0          0           0           0           0   \n",
       "1                 0          0           0           0           1   \n",
       "2                 0          0           0           0           0   \n",
       "3                 0          0           0           0           0   \n",
       "4                 0          0           0           0           0   \n",
       "...             ...        ...         ...         ...         ...   \n",
       "137136            0          0           0           0           0   \n",
       "137137            0          0           0           0           0   \n",
       "137138            0          0           0           0           0   \n",
       "137139            0          0           1           0           0   \n",
       "137140            0          0           0           0           0   \n",
       "\n",
       "       Fuel Type_N Fuel Type_X Fuel Type_Z  \n",
       "0                0           1           0  \n",
       "1                0           0           0  \n",
       "2                0           0           1  \n",
       "3                0           1           0  \n",
       "4                0           0           1  \n",
       "...            ...         ...         ...  \n",
       "137136           0           0           1  \n",
       "137137           0           1           0  \n",
       "137138           0           1           0  \n",
       "137139           0           1           0  \n",
       "137140           0           1           0  \n",
       "\n",
       "[137141 rows x 41 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_to_model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137141 entries, 0 to 137140\n",
      "Data columns (total 41 columns):\n",
      " #   Column                                 Non-Null Count   Dtype   \n",
      "---  ------                                 --------------   -----   \n",
      " 0   T_log_Fuel Consumption City (L/100Km)  137141 non-null  float64 \n",
      " 1   T_log_Fuel Consumption Hwy (L/100Km)   137141 non-null  float64 \n",
      " 2   T_log_Fuel Consumption Comb (L/100Km)  137141 non-null  float64 \n",
      " 3   T_log_Engine Size(L)                   137141 non-null  float64 \n",
      " 4   T_log_Cylinders                        137141 non-null  float64 \n",
      " 5   Vehicle Class_0                        137141 non-null  category\n",
      " 6   Vehicle Class_1                        137141 non-null  category\n",
      " 7   Vehicle Class_2                        137141 non-null  category\n",
      " 8   Vehicle Class_3                        137141 non-null  category\n",
      " 9   Vehicle Class_4                        137141 non-null  category\n",
      " 10  Transmission_0                         137141 non-null  category\n",
      " 11  Transmission_1                         137141 non-null  category\n",
      " 12  Transmission_2                         137141 non-null  category\n",
      " 13  Transmission_3                         137141 non-null  category\n",
      " 14  Transmission_4                         137141 non-null  category\n",
      " 15  Make_ASURA                             137141 non-null  category\n",
      " 16  Make_BARUSU                            137141 non-null  category\n",
      " 17  Make_BMV                               137141 non-null  category\n",
      " 18  Make_CADILUXE                          137141 non-null  category\n",
      " 19  Make_CHEVO                             137141 non-null  category\n",
      " 20  Make_DOGE                              137141 non-null  category\n",
      " 21  Make_FIAR                              137141 non-null  category\n",
      " 22  Make_FOLD                              137141 non-null  category\n",
      " 23  Make_FOLKSWA                           137141 non-null  category\n",
      " 24  Make_GONDA                             137141 non-null  category\n",
      " 25  Make_JIPU                              137141 non-null  category\n",
      " 26  Make_KIO                               137141 non-null  category\n",
      " 27  Make_LAMBOGI                           137141 non-null  category\n",
      " 28  Make_LAND CRAWLER                      137141 non-null  category\n",
      " 29  Make_LECUS                             137141 non-null  category\n",
      " 30  Make_MATSUDA                           137141 non-null  category\n",
      " 31  Make_MITSU                             137141 non-null  category\n",
      " 32  Make_NIRRAN                            137141 non-null  category\n",
      " 33  Make_RYUNDAI                           137141 non-null  category\n",
      " 34  Make_TOLVO                             137141 non-null  category\n",
      " 35  Make_TOYOTI                            137141 non-null  category\n",
      " 36  Fuel Type_D                            137141 non-null  category\n",
      " 37  Fuel Type_E                            137141 non-null  category\n",
      " 38  Fuel Type_N                            137141 non-null  category\n",
      " 39  Fuel Type_X                            137141 non-null  category\n",
      " 40  Fuel Type_Z                            137141 non-null  category\n",
      "dtypes: category(36), float64(5)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_to_model_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost\n",
    "- LGBM\n",
    "- DNN (NOT YET)\n",
    "- ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model_svr = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_dt = DecisionTreeRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_xgb = XGBRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model_lgbm = lgb.LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assuming you have training data X_train, y_train\n",
    "model_dnn = Sequential()\n",
    "model_dnn.add(\n",
    "    Dense(256, input_dim=df_train_to_model_log.shape[1], activation=\"relu\")\n",
    ")  # Input layer\n",
    "model_dnn.add(Dense(256, activation=\"relu\"))  # Hidden layer 1\n",
    "model_dnn.add(Dense(256, activation=\"relu\"))  # Hidden layer 2\n",
    "model_dnn.add(Dense(1))  # Output layer\n",
    "\n",
    "model_dnn.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "model_ensemble = StackingRegressor(estimators=[(\"xgb\", model_xgb), (\"lgbm\", model_lgbm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 1, Mean RMSE: 47.0105, Mean Training time: 0.6928 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 2, Mean RMSE: 47.0300, Mean Training time: 0.5955 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 3, Mean RMSE: 46.9846, Mean Training time: 0.8034 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 4, Mean RMSE: 46.9910, Mean Training time: 0.6066 seconds\n",
      "Model: XGBRegressor, Dataset: 1, Mean RMSE: 46.5683, Mean Training time: 0.8996 seconds\n",
      "Model: XGBRegressor, Dataset: 2, Mean RMSE: 46.5683, Mean Training time: 0.9705 seconds\n",
      "Model: XGBRegressor, Dataset: 3, Mean RMSE: 46.5683, Mean Training time: 0.8328 seconds\n",
      "Model: XGBRegressor, Dataset: 4, Mean RMSE: 46.6655, Mean Training time: 0.8392 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1131\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 1, Mean RMSE: 46.2847, Mean Training time: 9.3188 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1131\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 2, Mean RMSE: 46.2979, Mean Training time: 9.5636 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1131\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 3, Mean RMSE: 46.2725, Mean Training time: 10.7002 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1124\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1118\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1121\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 4, Mean RMSE: 46.3262, Mean Training time: 9.7626 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'models' is a list of your models\n",
    "models = [model_lgbm, model_xgb, model_ensemble]\n",
    "\n",
    "# Create a list of your datasets\n",
    "datasets = [\n",
    "    df_train_to_model_log,\n",
    "    df_train_to_model_sqrt,\n",
    "    df_train_to_model_boxcox,\n",
    "    df_train_to_model_inverse,\n",
    "]\n",
    "\n",
    "y = df_target\n",
    "\n",
    "# Initialize a dictionary to hold your results\n",
    "results = {}\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Loop over your models\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    results[model_name] = {}\n",
    "\n",
    "    # Loop over your datasets\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        results[model_name][f\"dataset_{i+1}\"] = {\n",
    "            \"rmse\": [],\n",
    "            \"training_time\": [],\n",
    "        }\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, test_index in kf.split(dataset):\n",
    "            X_train, X_test = dataset.iloc[train_index], dataset.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Create a StandardScaler object\n",
    "            scaler = StandardScaler()\n",
    "            # scaler = MinMaxScaler()\n",
    "\n",
    "            numerical_column = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "            non_numerical_columns = [\n",
    "                col for col in X_train.columns if col not in numerical_column\n",
    "            ]\n",
    "            for col in non_numerical_columns:\n",
    "                X_train.loc[:, col] = X_train.loc[:, col].astype(\"int64\")\n",
    "                X_test.loc[:, col] = X_test.loc[:, col].astype(\"int64\")\n",
    "\n",
    "            # Normalize the data\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # Start the timer\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # End the timer\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Calculate the training time\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            # Store the results\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"].append(rmse)\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"].append(training_time)\n",
    "\n",
    "        # Calculate the mean RMSE and training time\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"rmse\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"]\n",
    "        )\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"training_time\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"]\n",
    "        )\n",
    "\n",
    "        # Print the process\n",
    "        print(\n",
    "            f\"Model: {model_name}, Dataset: {i+1}, Mean RMSE: {results[model_name][f'dataset_{i+1}']['rmse']:.4f}, Mean Training time: {results[model_name][f'dataset_{i+1}']['training_time']:.4f} seconds\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LGBMRegressor': {'dataset_1': {'rmse': 47.010510067031376,\n",
       "   'training_time': 0.6927943706512452},\n",
       "  'dataset_2': {'rmse': 47.03002967621724,\n",
       "   'training_time': 0.5955313682556153},\n",
       "  'dataset_3': {'rmse': 46.98460041174822,\n",
       "   'training_time': 0.8033969402313232},\n",
       "  'dataset_4': {'rmse': 46.99100386720102,\n",
       "   'training_time': 0.6065879821777344}},\n",
       " 'XGBRegressor': {'dataset_1': {'rmse': 46.56833158289303,\n",
       "   'training_time': 0.8996120929718018},\n",
       "  'dataset_2': {'rmse': 46.56833158289303,\n",
       "   'training_time': 0.9704749107360839},\n",
       "  'dataset_3': {'rmse': 46.56833158289303,\n",
       "   'training_time': 0.8328103065490723},\n",
       "  'dataset_4': {'rmse': 46.66546281768829,\n",
       "   'training_time': 0.839204216003418}},\n",
       " 'StackingRegressor': {'dataset_1': {'rmse': 46.28465319492201,\n",
       "   'training_time': 9.318825578689575},\n",
       "  'dataset_2': {'rmse': 46.297879233974115, 'training_time': 9.56360936164856},\n",
       "  'dataset_3': {'rmse': 46.27246964024506,\n",
       "   'training_time': 10.700177907943726},\n",
       "  'dataset_4': {'rmse': 46.326187438908875,\n",
       "   'training_time': 9.762559127807616}}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>47.010510</td>\n",
       "      <td>0.692794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>47.030030</td>\n",
       "      <td>0.595531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.984600</td>\n",
       "      <td>0.803397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.991004</td>\n",
       "      <td>0.606588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.568332</td>\n",
       "      <td>0.899612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.568332</td>\n",
       "      <td>0.970475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.568332</td>\n",
       "      <td>0.832810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.665463</td>\n",
       "      <td>0.839204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.284653</td>\n",
       "      <td>9.318826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.297879</td>\n",
       "      <td>9.563609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.272470</td>\n",
       "      <td>10.700178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.326187</td>\n",
       "      <td>9.762559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Dataset       RMSE  Training Time\n",
       "0       LGBMRegressor  dataset_1  47.010510       0.692794\n",
       "1       LGBMRegressor  dataset_2  47.030030       0.595531\n",
       "2       LGBMRegressor  dataset_3  46.984600       0.803397\n",
       "3       LGBMRegressor  dataset_4  46.991004       0.606588\n",
       "4        XGBRegressor  dataset_1  46.568332       0.899612\n",
       "5        XGBRegressor  dataset_2  46.568332       0.970475\n",
       "6        XGBRegressor  dataset_3  46.568332       0.832810\n",
       "7        XGBRegressor  dataset_4  46.665463       0.839204\n",
       "8   StackingRegressor  dataset_1  46.284653       9.318826\n",
       "9   StackingRegressor  dataset_2  46.297879       9.563609\n",
       "10  StackingRegressor  dataset_3  46.272470      10.700178\n",
       "11  StackingRegressor  dataset_4  46.326187       9.762559"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the nested dictionary into a pandas DataFrame\n",
    "df_results = pd.concat({k: pd.DataFrame(v).T for k, v in results.items()}, axis=0)\n",
    "\n",
    "# Reset the index and rename the columns for a cleaner look\n",
    "df_results.reset_index(inplace=True)\n",
    "df_results.columns = [\"Model\", \"Dataset\", \"RMSE\", \"Training Time\"]\n",
    "\n",
    "df_results.to_csv(\"results_3.csv\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.272470</td>\n",
       "      <td>10.700178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.284653</td>\n",
       "      <td>9.318826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.297879</td>\n",
       "      <td>9.563609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.326187</td>\n",
       "      <td>9.762559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.568332</td>\n",
       "      <td>0.899612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.568332</td>\n",
       "      <td>0.970475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.568332</td>\n",
       "      <td>0.832810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.665463</td>\n",
       "      <td>0.839204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.984600</td>\n",
       "      <td>0.803397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.991004</td>\n",
       "      <td>0.606588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>47.010510</td>\n",
       "      <td>0.692794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>47.030030</td>\n",
       "      <td>0.595531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Dataset       RMSE  Training Time\n",
       "10  StackingRegressor  dataset_3  46.272470      10.700178\n",
       "8   StackingRegressor  dataset_1  46.284653       9.318826\n",
       "9   StackingRegressor  dataset_2  46.297879       9.563609\n",
       "11  StackingRegressor  dataset_4  46.326187       9.762559\n",
       "4        XGBRegressor  dataset_1  46.568332       0.899612\n",
       "5        XGBRegressor  dataset_2  46.568332       0.970475\n",
       "6        XGBRegressor  dataset_3  46.568332       0.832810\n",
       "7        XGBRegressor  dataset_4  46.665463       0.839204\n",
       "2       LGBMRegressor  dataset_3  46.984600       0.803397\n",
       "3       LGBMRegressor  dataset_4  46.991004       0.606588\n",
       "0       LGBMRegressor  dataset_1  47.010510       0.692794\n",
       "1       LGBMRegressor  dataset_2  47.030030       0.595531"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df_results.sort_values(by=\"RMSE\", ascending=True)\n",
    "df_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv31011",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
