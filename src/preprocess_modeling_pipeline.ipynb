{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../dataset/train_cleaned_outliers_imputed.csv\")\n",
    "df_train_id = df_train.pop(\"Id\")\n",
    "df_train_target = df_train.pop(\"CO2 Emissions(g/km)\")\n",
    "\n",
    "df_test = pd.read_csv(\"../dataset/test_cleaned_outliers_imputed.csv\")\n",
    "df_test_id = df_test.pop(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>Engine Size(L)</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>Fuel Consumption City</th>\n",
       "      <th>Fuel Consumption Hwy</th>\n",
       "      <th>Fuel Consumption Comb</th>\n",
       "      <th>Transmission_Type</th>\n",
       "      <th>Gears</th>\n",
       "      <th>Vehicle Class General</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MITSU</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AV8</td>\n",
       "      <td>X</td>\n",
       "      <td>11.904762</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>8</td>\n",
       "      <td>SUV</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOYOTI</td>\n",
       "      <td>PICKUP TRUCK - SMALL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>A5</td>\n",
       "      <td>X</td>\n",
       "      <td>13.793103</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>11.960000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>5</td>\n",
       "      <td>PICKUP TRUCK</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MATSUDA</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "      <td>10.204082</td>\n",
       "      <td>7.299251</td>\n",
       "      <td>8.894238</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEVO</td>\n",
       "      <td>VAN - PASSENGER</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>A6</td>\n",
       "      <td>X</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>14.780000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>6</td>\n",
       "      <td>VAN</td>\n",
       "      <td>PASSENGER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOYOTI</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M6</td>\n",
       "      <td>X</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>7.899357</td>\n",
       "      <td>8.010000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>6</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54932</th>\n",
       "      <td>CHEVO</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AS10</td>\n",
       "      <td>Z</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>8.802817</td>\n",
       "      <td>10.505341</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>10</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54933</th>\n",
       "      <td>CHEVO</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>M6</td>\n",
       "      <td>X</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>16.323011</td>\n",
       "      <td>Manual</td>\n",
       "      <td>6</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54934</th>\n",
       "      <td>FOLD</td>\n",
       "      <td>TWO-SEATER</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AM7</td>\n",
       "      <td>Z</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>15.630000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>7</td>\n",
       "      <td>TWO-SEATER</td>\n",
       "      <td>TWO-SEATER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54935</th>\n",
       "      <td>CHEVO</td>\n",
       "      <td>PICKUP TRUCK - STANDARD</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>A8</td>\n",
       "      <td>Z</td>\n",
       "      <td>18.300000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>14.520000</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>8</td>\n",
       "      <td>PICKUP TRUCK</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54936</th>\n",
       "      <td>RYUNDAI</td>\n",
       "      <td>FULL-SIZE</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>7.300266</td>\n",
       "      <td>8.665511</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>6</td>\n",
       "      <td>FULL-SIZE</td>\n",
       "      <td>FULL-SIZE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54937 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Make            Vehicle Class  Engine Size(L)  Cylinders  \\\n",
       "0        MITSU              SUV - SMALL             1.5        4.0   \n",
       "1       TOYOTI     PICKUP TRUCK - SMALL             4.0        6.0   \n",
       "2      MATSUDA                  COMPACT             2.0        4.0   \n",
       "3        CHEVO          VAN - PASSENGER             6.0        8.0   \n",
       "4       TOYOTI                  COMPACT             1.8        4.0   \n",
       "...        ...                      ...             ...        ...   \n",
       "54932    CHEVO               SUBCOMPACT             6.2        8.0   \n",
       "54933    CHEVO               SUBCOMPACT             3.6        6.0   \n",
       "54934     FOLD               TWO-SEATER             3.5        6.0   \n",
       "54935    CHEVO  PICKUP TRUCK - STANDARD             6.2        8.0   \n",
       "54936  RYUNDAI                FULL-SIZE             2.4        4.0   \n",
       "\n",
       "      Transmission Fuel Type  Fuel Consumption City  Fuel Consumption Hwy  \\\n",
       "0              AV8         X              11.904762              7.200000   \n",
       "1               A5         X              13.793103              9.700000   \n",
       "2              AS6         X              10.204082              7.299251   \n",
       "3               A6         X              17.300000             11.700000   \n",
       "4               M6         X               8.100000              7.899357   \n",
       "...            ...       ...                    ...                   ...   \n",
       "54932         AS10         Z              11.900000              8.802817   \n",
       "54933           M6         X              21.000000             10.600000   \n",
       "54934          AM7         Z              18.200000             12.500000   \n",
       "54935           A8         Z              18.300000              9.900000   \n",
       "54936          AS6         X               9.700000              7.300266   \n",
       "\n",
       "       Fuel Consumption Comb Transmission_Type  Gears Vehicle Class General  \\\n",
       "0                   9.800000         Automatic      8                   SUV   \n",
       "1                  11.960000         Automatic      5          PICKUP TRUCK   \n",
       "2                   8.894238         Automatic      6               COMPACT   \n",
       "3                  14.780000         Automatic      6                   VAN   \n",
       "4                   8.010000            Manual      6               COMPACT   \n",
       "...                      ...               ...    ...                   ...   \n",
       "54932              10.505341         Automatic     10            SUBCOMPACT   \n",
       "54933              16.323011            Manual      6            SUBCOMPACT   \n",
       "54934              15.630000         Automatic      7            TWO-SEATER   \n",
       "54935              14.520000         Automatic      8          PICKUP TRUCK   \n",
       "54936               8.665511         Automatic      6             FULL-SIZE   \n",
       "\n",
       "      Vehicle Type  is_outlier  \n",
       "0            SMALL           0  \n",
       "1            SMALL           0  \n",
       "2          COMPACT           0  \n",
       "3        PASSENGER           0  \n",
       "4          COMPACT           0  \n",
       "...            ...         ...  \n",
       "54932   SUBCOMPACT           1  \n",
       "54933   SUBCOMPACT           0  \n",
       "54934   TWO-SEATER           0  \n",
       "54935     STANDARD           1  \n",
       "54936    FULL-SIZE           0  \n",
       "\n",
       "[54937 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import BinaryEncoder, OrdinalEncoder\n",
    "\n",
    "\n",
    "def encode_categorical_features(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    categorical_features_onehot,\n",
    "    categorical_features_binary,\n",
    "    categorical_features_ordinal,\n",
    "):\n",
    "    df_train_categorical_one_hot = df_train[categorical_features_onehot]\n",
    "    df_train_categorical_binary = df_train[categorical_features_binary]\n",
    "    df_train_categorical_ordinal = df_train[categorical_features_ordinal]\n",
    "\n",
    "    df_test_categorical_one_hot = df_test[categorical_features_onehot]\n",
    "    df_test_categorical_binary = df_test[categorical_features_binary]\n",
    "    df_test_categorical_ordinal = df_test[categorical_features_ordinal]\n",
    "\n",
    "    encoder_onehot = OneHotEncoder(sparse_output=False)\n",
    "    train_onehot_encoded_data = encoder_onehot.fit_transform(\n",
    "        df_train_categorical_one_hot\n",
    "    )\n",
    "    test_onehot_encoded_data = encoder_onehot.transform(df_test_categorical_one_hot)\n",
    "\n",
    "    # Convert numpy arrays to pandas DataFrames\n",
    "    train_onehot_encoded_data = pd.DataFrame(\n",
    "        train_onehot_encoded_data,\n",
    "        columns=encoder_onehot.get_feature_names_out(categorical_features_onehot),\n",
    "        index=df_train.index,\n",
    "    )\n",
    "    test_onehot_encoded_data = pd.DataFrame(\n",
    "        test_onehot_encoded_data,\n",
    "        columns=encoder_onehot.get_feature_names_out(categorical_features_onehot),\n",
    "        index=df_test.index,\n",
    "    )\n",
    "\n",
    "    encoder_binary = BinaryEncoder(cols=categorical_features_binary)\n",
    "    train_df_binary = encoder_binary.fit_transform(df_train_categorical_binary)\n",
    "    test_df_binary = encoder_binary.transform(df_test_categorical_binary)\n",
    "\n",
    "    encoder_ordinal = OrdinalEncoder(cols=categorical_features_ordinal)\n",
    "    train_df_ordinal = encoder_ordinal.fit_transform(df_train_categorical_ordinal)\n",
    "    test_df_ordinal = encoder_ordinal.transform(df_test_categorical_ordinal)\n",
    "\n",
    "    # Merge the one-hot, binary and ordinal encoded dataframes with the original dataframes\n",
    "    df_train = pd.concat(\n",
    "        [\n",
    "            df_train.drop(\n",
    "                categorical_features_onehot\n",
    "                + categorical_features_binary\n",
    "                + categorical_features_ordinal,\n",
    "                axis=1,\n",
    "            ),\n",
    "            train_onehot_encoded_data,\n",
    "            train_df_binary,\n",
    "            train_df_ordinal,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    df_test = pd.concat(\n",
    "        [\n",
    "            df_test.drop(\n",
    "                categorical_features_onehot\n",
    "                + categorical_features_binary\n",
    "                + categorical_features_ordinal,\n",
    "                axis=1,\n",
    "            ),\n",
    "            test_onehot_encoded_data,\n",
    "            test_df_binary,\n",
    "            test_df_ordinal,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54937 entries, 0 to 54936\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Make                   54937 non-null  object \n",
      " 1   Vehicle Class          54937 non-null  object \n",
      " 2   Engine Size(L)         54937 non-null  float64\n",
      " 3   Cylinders              54937 non-null  float64\n",
      " 4   Transmission           54937 non-null  object \n",
      " 5   Fuel Type              54937 non-null  object \n",
      " 6   Fuel Consumption City  54937 non-null  float64\n",
      " 7   Fuel Consumption Hwy   54937 non-null  float64\n",
      " 8   Fuel Consumption Comb  54937 non-null  float64\n",
      " 9   Transmission_Type      54937 non-null  object \n",
      " 10  Gears                  54937 non-null  int64  \n",
      " 11  Vehicle Class General  54937 non-null  object \n",
      " 12  Vehicle Type           54937 non-null  object \n",
      " 13  is_outlier             54937 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(7)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n",
    "\n",
    "onehot_columns = [\"Make\", \"Fuel Type\", \"Transmission_Type\", \"Vehicle Class General\", \"Gears\", \"is_outlier\"]\n",
    "binary_columns = [\"Vehicle Class\", \"Transmission\"]\n",
    "ordinal_columns = [\"Vehicle Type\"]\n",
    "\n",
    "numerical_columns = df_train.select_dtypes(include='float64').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = encode_categorical_features(df_train, df_test, onehot_columns, binary_columns, ordinal_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def minmax_transform_dataframe(df_train, df_test, columns_to_transform):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    transformed_data_train = scaler.fit_transform(df_train[columns_to_transform])\n",
    "    transformed_df_train = pd.DataFrame(\n",
    "        transformed_data_train, columns=columns_to_transform, index=df_train.index\n",
    "    )\n",
    "    df_train[columns_to_transform] = transformed_df_train\n",
    "\n",
    "    transformed_data_test = scaler.transform(df_test[columns_to_transform])\n",
    "    transformed_df_test = pd.DataFrame(\n",
    "        transformed_data_test, columns=columns_to_transform, index=df_test.index\n",
    "    )\n",
    "    df_test[columns_to_transform] = transformed_df_test\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "model_lgbm = lgb.LGBMRegressor(random_state=random_state)\n",
    "model_xgb = XGBRegressor(random_state=random_state)\n",
    "model_adab = AdaBoostRegressor(random_state=random_state)\n",
    "\n",
    "\n",
    "model_ensemble = StackingRegressor(\n",
    "    estimators=[(\"xgb\", model_xgb), (\"lgbm\", model_lgbm), (\"adab\", model_adab)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43949, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.828438\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43949, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.482036\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.926576\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.605575\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.600774\n",
      "Model: LGBMRegressor, Dataset: 1, Mean RMSE: 20.3396, Mean Training time: 0.7384 seconds\n",
      "Model: XGBRegressor, Dataset: 1, Mean RMSE: 19.8130, Mean Training time: 0.4747 seconds\n",
      "Model: AdaBoostRegressor, Dataset: 1, Mean RMSE: 32.5413, Mean Training time: 8.1656 seconds\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43949, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.828438\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.826104\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.672658\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.717114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 247.002474\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.923834\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43949, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.482036\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.681134\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.345232\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.205808\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35159, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.575102\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.602901\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.926576\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.947383\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.863168\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.747639\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 247.003811\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 247.070876\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.605575\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.672981\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.431342\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.406968\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.773493\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.743089\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.600774\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.737998\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.394454\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.306627\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.591837\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 35160, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.972952\n",
      "Model: StackingRegressor, Dataset: 1, Mean RMSE: 19.7227, Mean Training time: 47.3118 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'models' is a list of your models\n",
    "models = [model_lgbm, model_xgb, model_adab, model_ensemble]\n",
    "\n",
    "# Create a list of your datasets\n",
    "datasets = [\n",
    "    df_train,\n",
    "]\n",
    "\n",
    "y = df_train_target\n",
    "\n",
    "# Initialize a dictionary to hold your results\n",
    "results = {}\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Loop over your models\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    results[model_name] = {}\n",
    "\n",
    "    # Loop over your datasets\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        results[model_name][f\"dataset_{i+1}\"] = {\n",
    "            \"rmse\": [],\n",
    "            \"training_time\": [],\n",
    "        }\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, test_index in kf.split(dataset):\n",
    "            X_train, X_test = dataset.iloc[train_index], dataset.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Preprocess the data\n",
    "            X_train, X_test = encode_categorical_features(\n",
    "                X_train,\n",
    "                X_test,\n",
    "                onehot_columns,\n",
    "                binary_columns,\n",
    "                ordinal_columns,\n",
    "            )\n",
    "\n",
    "            X_train, X_test = minmax_transform_dataframe(\n",
    "                X_train, X_test, numerical_columns\n",
    "            )\n",
    "\n",
    "            # Start the timer\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # End the timer\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Calculate the training time\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            # Store the results\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"].append(rmse)\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"].append(training_time)\n",
    "\n",
    "        # Calculate the mean RMSE and training time\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"rmse\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"]\n",
    "        )\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"training_time\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"]\n",
    "        )\n",
    "\n",
    "        # Print the process\n",
    "        print(\n",
    "            f\"Model: {model_name}, Dataset: {i+1}, Mean RMSE: {results[model_name][f'dataset_{i+1}']['rmse']:.4f}, Mean Training time: {results[model_name][f'dataset_{i+1}']['training_time']:.4f} seconds\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>19.722697</td>\n",
       "      <td>47.311763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>19.812993</td>\n",
       "      <td>0.474668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>20.339575</td>\n",
       "      <td>0.738387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>32.541271</td>\n",
       "      <td>8.165611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Dataset       RMSE  Training Time\n",
       "3  StackingRegressor  dataset_1  19.722697      47.311763\n",
       "1       XGBRegressor  dataset_1  19.812993       0.474668\n",
       "0      LGBMRegressor  dataset_1  20.339575       0.738387\n",
       "2  AdaBoostRegressor  dataset_1  32.541271       8.165611"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the nested dictionary into a pandas DataFrame\n",
    "df_results = pd.concat({k: pd.DataFrame(v).T for k, v in results.items()}, axis=0)\n",
    "\n",
    "# Reset the index and rename the columns for a cleaner look\n",
    "df_results.reset_index(inplace=True)\n",
    "df_results.columns = [\"Model\", \"Dataset\", \"RMSE\", \"Training Time\"]\n",
    "\n",
    "df_results.to_csv(\"results_to_submit.csv\")\n",
    "df_sorted = df_results.sort_values(by=\"RMSE\", ascending=True)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 54937, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.688680\n",
      "Model: LGBMRegressor, Dataset: 1, Training time: 1.0980 seconds\n",
      "Model: XGBRegressor, Dataset: 1, Training time: 0.9959 seconds\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 54937, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.688680\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43949, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.769096\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43949, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.555599\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.474767\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.778862\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 945\n",
      "[LightGBM] [Info] Number of data points in the train set: 43950, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score 246.865074\n",
      "Model: StackingRegressor, Dataset: 1, Training time: 58.5295 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'models' is a list of your models\n",
    "models = [model_lgbm, model_xgb, model_adab, model_ensemble]\n",
    "\n",
    "# Create a list of your train datasets\n",
    "train_datasets = [df_train]\n",
    "\n",
    "# Create a list of your test datasets\n",
    "test_datasets = [df_test]\n",
    "\n",
    "y = df_train_target\n",
    "\n",
    "# Initialize a dictionary to hold your results\n",
    "results = {}\n",
    "\n",
    "# Loop over your models\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    results[model_name] = {}\n",
    "\n",
    "    # Loop over your datasets\n",
    "    for i, (train_dataset, test_dataset) in enumerate(\n",
    "        zip(train_datasets, test_datasets)\n",
    "    ):\n",
    "        results[model_name][f\"dataset_{i+1}\"] = {\n",
    "            \"predictions\": [],\n",
    "            \"training_time\": [],\n",
    "        }\n",
    "\n",
    "        X_train = train_dataset\n",
    "        y_train = y\n",
    "\n",
    "        X_test = test_dataset\n",
    "\n",
    "        X_train, X_test = encode_categorical_features(\n",
    "            X_train,\n",
    "            X_test,\n",
    "            onehot_columns,\n",
    "            binary_columns,\n",
    "            ordinal_columns,\n",
    "        )\n",
    "\n",
    "        X_train, X_test = minmax_transform_dataframe(X_train, X_test, numerical_columns)\n",
    "\n",
    "        # Start the timer\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # End the timer\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate the training time\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Store the results\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"predictions\"] = predictions\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"training_time\"] = training_time\n",
    "\n",
    "        # Print the process\n",
    "        print(\n",
    "            f\"Model: {model_name}, Dataset: {i+1}, Training time: {results[model_name][f'dataset_{i+1}']['training_time']:.4f} seconds\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>predictions</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>[342.9385418176665, 196.41416644463698, 206.71...</td>\n",
       "      <td>1.098003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>[340.5571, 198.10645, 210.54256, 226.43877, 22...</td>\n",
       "      <td>0.995932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>[341.21726802417356, 198.22696093600297, 209.6...</td>\n",
       "      <td>58.529468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name dataset_name  \\\n",
       "0      LGBMRegressor    dataset_1   \n",
       "1       XGBRegressor    dataset_1   \n",
       "2  StackingRegressor    dataset_1   \n",
       "\n",
       "                                         predictions  training_time  \n",
       "0  [342.9385418176665, 196.41416644463698, 206.71...       1.098003  \n",
       "1  [340.5571, 198.10645, 210.54256, 226.43877, 22...       0.995932  \n",
       "2  [341.21726802417356, 198.22696093600297, 209.6...      58.529468  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the results dictionary\n",
    "flat_results = []\n",
    "for model_name, datasets in results.items():\n",
    "    for dataset_name, metrics in datasets.items():\n",
    "        flat_results.append(\n",
    "            {\n",
    "                \"model_name\": model_name,\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"predictions\": metrics[\"predictions\"],\n",
    "                \"training_time\": metrics[\"training_time\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert the flattened results to a DataFrame\n",
    "df_results_submit = pd.DataFrame(flat_results)\n",
    "df_results_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([341.21726802, 198.22696094, 209.6497149 , ..., 235.4348188 ,\n",
       "       228.40777772, 333.49953058])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_regressor_predictions = results[\"StackingRegressor\"][\"dataset_1\"][\n",
    "    \"predictions\"\n",
    "]\n",
    "stacking_regressor_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CO2 Emissions(g/km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54938</td>\n",
       "      <td>341.217268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54939</td>\n",
       "      <td>198.226961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54940</td>\n",
       "      <td>209.649715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54941</td>\n",
       "      <td>230.567111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54942</td>\n",
       "      <td>225.848619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23540</th>\n",
       "      <td>78478</td>\n",
       "      <td>213.472628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23541</th>\n",
       "      <td>78479</td>\n",
       "      <td>170.312235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23542</th>\n",
       "      <td>78480</td>\n",
       "      <td>235.434819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23543</th>\n",
       "      <td>78481</td>\n",
       "      <td>228.407778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23544</th>\n",
       "      <td>78482</td>\n",
       "      <td>333.499531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23545 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  CO2 Emissions(g/km)\n",
       "0      54938           341.217268\n",
       "1      54939           198.226961\n",
       "2      54940           209.649715\n",
       "3      54941           230.567111\n",
       "4      54942           225.848619\n",
       "...      ...                  ...\n",
       "23540  78478           213.472628\n",
       "23541  78479           170.312235\n",
       "23542  78480           235.434819\n",
       "23543  78481           228.407778\n",
       "23544  78482           333.499531\n",
       "\n",
       "[23545 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission = pd.read_csv(\"../dataset/sample_submission.csv\")\n",
    "df_sample_submission[\"CO2 Emissions(g/km)\"] = stacking_regressor_predictions\n",
    "df_sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission.to_csv(\"../submit/submission_stacking_regressor.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv31011",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
