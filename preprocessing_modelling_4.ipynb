{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"./dataset/train_preprocessed_imputed_preprocessed.csv\")\n",
    "# df_target = df_train.pop(\"CO2 Emissions(g/km)\")\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(\"./dataset/test_preprocessed.csv\")\n",
    "# df_test.rename(\n",
    "#     columns={\n",
    "#         \"Fuel Consumption City\": \"Fuel Consumption City (L/100Km)\",\n",
    "#         \"Fuel Consumption Hwy\": \"Fuel Consumption Hwy (L/100Km)\",\n",
    "#         \"Fuel Consumption Comb\": \"Fuel Consumption Comb (L/100Km)\",\n",
    "#     },\n",
    "#     inplace=True,\n",
    "# )\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = pd.concat([df_train, df_test])\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fuelconsumption = df_all[\n",
    "#     [\n",
    "#         \"Fuel Consumption City (L/100Km)\",\n",
    "#         \"Fuel Consumption Hwy (L/100Km)\",\n",
    "#         \"Fuel Consumption Comb (L/100Km)\",\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# df_enginecylinders = df_all[\n",
    "#     # [\"Engine Size(L)\", \"Cylinders\", \"CO2 Emissions(g/km)\", \"Make\", \"Vehicle Class\"] # with category features\n",
    "#     [\"Engine Size(L)\", \"Cylinders\"]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "\n",
    "# imp = IterativeImputer(random_state=42)\n",
    "# imp.set_output(transform=\"pandas\")\n",
    "# imp.fit(df_fuelconsumption)\n",
    "# df_fuelconsumption_imputed = imp.transform(df_fuelconsumption)\n",
    "\n",
    "# imp = IterativeImputer(random_state=42)\n",
    "# imp.set_output(transform=\"pandas\")\n",
    "# imp.fit(df_enginecylinders)\n",
    "# df_enginecylinders_imputed = imp.transform(df_enginecylinders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add data to df_all_fix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # there were data < 0, so we need to replace it with 0\n",
    "\n",
    "# df_numerical_imputed = pd.concat(\n",
    "#     [df_fuelconsumption_imputed, df_enginecylinders_imputed], axis=1\n",
    "# )\n",
    "# df_numerical_imputed = df_numerical_imputed.clip(lower=0)\n",
    "\n",
    "# df_numerical_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix1 = df_all.drop(df_numerical_imputed.columns.tolist(), axis=1)\n",
    "# df_fix1 = pd.concat([df_fix1, df_numerical_imputed], axis=1)\n",
    "# df_fix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_categorical_imputed = df_fix1[\n",
    "#     [\n",
    "#         \"Make\",\n",
    "#         \"Vehicle Class\",\n",
    "#         \"Transmission\",\n",
    "#         \"Fuel Type\",\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#         \"Engine Size(L)\",\n",
    "#         \"Cylinders\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# for col in df_categorical_imputed.columns:\n",
    "#     if df_categorical_imputed[col].dtype == \"object\":\n",
    "#         df_categorical_imputed[col] = df_categorical_imputed[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import miceforest as mf\n",
    "\n",
    "# # might consider \"UserWarning: [Transmission,Fuel Type] have very rare categories, it is a good idea to group these, or set the min_data_in_leaf parameter to prevent lightgbm from outputting 0.0 probabilities.\"\n",
    "\n",
    "# kds = mf.ImputationKernel(\n",
    "#     df_categorical_imputed, save_all_iterations=True, random_state=42\n",
    "# )\n",
    "# kds.mice(10)\n",
    "# df_categorical_imputed = kds.complete_data()\n",
    "\n",
    "# df_categorical_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_categorical_impupted_fix = df_categorical_imputed.copy()\n",
    "# df_categorical_impupted_fix = df_categorical_impupted_fix.drop(\n",
    "#     [\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#         \"Engine Size(L)\",\n",
    "#         \"Cylinders\",\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix2 = df_fix1.drop(df_categorical_impupted_fix.columns.tolist(), axis=1)\n",
    "# df_fix2 = pd.concat([df_fix2, df_categorical_impupted_fix], axis=1)\n",
    "# df_fix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix3 = df_fix2.copy()\n",
    "# df_fix3.reset_index(drop=True, inplace=True)\n",
    "# df_fix3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix = df_fix3.iloc[:df_train.shape[0], :]\n",
    "# df_train_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_fix = df_fix3.iloc[df_train.shape[0] :, :]\n",
    "# df_test_fix.reset_index(drop=True, inplace=True)\n",
    "# df_test_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix = pd.concat([df_train_fix, df_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix.to_csv(\"./dataset/train_fix.csv\", index=False)\n",
    "# df_test_fix.to_csv(\"./dataset/test_fix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dython.nominal import associations\n",
    "\n",
    "# associations(df_train_fix)\n",
    "# associations(df_test_fix)\n",
    "# associations(df_fix3)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fix = pd.read_csv(\"./dataset/train_fix.csv\")\n",
    "df_test_fix = pd.read_csv(\"./dataset/test_fix.csv\")\n",
    "df_train_target = df_train_fix.pop(\"CO2 Emissions(g/km)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Value:\n",
    "- Fuel Consumption City (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Fuel Consumption Hwy (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Fuel Consumption Comb (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Engine Size(L) -> log, sqrt, boxcox, inverse\n",
    "- Cylinders -> log, sqrt, boxcox, inverse\n",
    "\n",
    "Categorical Value:\n",
    "- Make -> one-hot\n",
    "- Vehicle Class -> binary\n",
    "- Transmission -> binary \n",
    "- Fuel Type -> one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fix_preprocessed = df_train_fix.copy()\n",
    "df_test_fix_preprocessed = df_test_fix.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Fuel Consumption City (L/100Km)</th>\n",
       "      <th>Fuel Consumption Hwy (L/100Km)</th>\n",
       "      <th>Fuel Consumption Comb (L/100Km)</th>\n",
       "      <th>Engine Size(L)</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Make</th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Fuel Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.640000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>7.514791</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>FOLD</td>\n",
       "      <td>PICKUP TRUCK - STANDARD</td>\n",
       "      <td>A6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>28.840000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CHEVO</td>\n",
       "      <td>PICKUP TRUCK - STANDARD</td>\n",
       "      <td>A6</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>1.848477</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BMV</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>M6</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15.337423</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>15.590609</td>\n",
       "      <td>2.057097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>KIO</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.150000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BARUSU</td>\n",
       "      <td>MINICOMPACT</td>\n",
       "      <td>AS6</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137136</th>\n",
       "      <td>137137</td>\n",
       "      <td>33.710000</td>\n",
       "      <td>7.698229</td>\n",
       "      <td>22.026432</td>\n",
       "      <td>5.023977</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BMV</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>AS8</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137137</th>\n",
       "      <td>137138</td>\n",
       "      <td>6.489293</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>3.961175</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GONDA</td>\n",
       "      <td>STATION WAGON - SMALL</td>\n",
       "      <td>M6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137138</th>\n",
       "      <td>137139</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>5.412550</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NIRRAN</td>\n",
       "      <td>MID-SIZE</td>\n",
       "      <td>AV</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137139</th>\n",
       "      <td>137140</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>0.221408</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TOYOTI</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>AV</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137140</th>\n",
       "      <td>137141</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.098853</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BARUSU</td>\n",
       "      <td>MID-SIZE</td>\n",
       "      <td>AV6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137141 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Fuel Consumption City (L/100Km)  \\\n",
       "0            1                         8.640000   \n",
       "1            2                        27.270000   \n",
       "2            3                         1.700000   \n",
       "3            4                        15.337423   \n",
       "4            5                        20.150000   \n",
       "...        ...                              ...   \n",
       "137136  137137                        33.710000   \n",
       "137137  137138                         6.489293   \n",
       "137138  137139                         2.990000   \n",
       "137139  137140                        11.480000   \n",
       "137140  137141                         3.360000   \n",
       "\n",
       "        Fuel Consumption Hwy (L/100Km)  Fuel Consumption Comb (L/100Km)  \\\n",
       "0                             6.140000                         7.514791   \n",
       "1                            30.760000                        28.840000   \n",
       "2                             2.030000                         1.848477   \n",
       "3                            15.900000                        15.590609   \n",
       "4                             6.000000                        13.800000   \n",
       "...                                ...                              ...   \n",
       "137136                        7.698229                        22.026432   \n",
       "137137                        0.870000                         3.961175   \n",
       "137138                        8.380000                         5.412550   \n",
       "137139                        0.221408                         6.400000   \n",
       "137140                        2.800000                         3.098853   \n",
       "\n",
       "        Engine Size(L)  Cylinders    Make            Vehicle Class  \\\n",
       "0             3.500000        6.0    FOLD  PICKUP TRUCK - STANDARD   \n",
       "1             5.300000        8.0   CHEVO  PICKUP TRUCK - STANDARD   \n",
       "2             4.400000        6.0     BMV               SUBCOMPACT   \n",
       "3             2.057097        4.0     KIO              SUV - SMALL   \n",
       "4             3.000000        6.0  BARUSU              MINICOMPACT   \n",
       "...                ...        ...     ...                      ...   \n",
       "137136        5.023977        8.0     BMV               SUBCOMPACT   \n",
       "137137        1.500000        4.0   GONDA    STATION WAGON - SMALL   \n",
       "137138        1.800000        4.0  NIRRAN                 MID-SIZE   \n",
       "137139        1.800000        4.0  TOYOTI                  COMPACT   \n",
       "137140        2.500000        4.0  BARUSU                 MID-SIZE   \n",
       "\n",
       "       Transmission Fuel Type  \n",
       "0                A6         X  \n",
       "1                A6         E  \n",
       "2                M6         Z  \n",
       "3               AS6         X  \n",
       "4               AS6         Z  \n",
       "...             ...       ...  \n",
       "137136          AS8         Z  \n",
       "137137           M6         X  \n",
       "137138           AV         X  \n",
       "137139           AV         X  \n",
       "137140          AV6         X  \n",
       "\n",
       "[137141 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fix_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PowerTransformer <- MIGHT USE THIS\n",
    "\n",
    "column_to_transform = [\n",
    "    \"Fuel Consumption City (L/100Km)\",\n",
    "    \"Fuel Consumption Hwy (L/100Km)\",\n",
    "    \"Fuel Consumption Comb (L/100Km)\",\n",
    "    \"Engine Size(L)\",\n",
    "    \"Cylinders\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_log_\"+col] = np.log(df_train_fix_preprocessed[col] + 1)\n",
    "    df_test_fix_preprocessed[\"T_log_\"+col] = np.log(df_test_fix_preprocessed[col] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_sqrt_\"+col] = np.sqrt(df_train_fix_preprocessed[col])\n",
    "    df_test_fix_preprocessed[\"T_sqrt_\"+col] = np.sqrt(df_test_fix_preprocessed[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_boxcox_\"+col], _ = stats.boxcox(\n",
    "        df_train_fix_preprocessed[col] + 1\n",
    "    )\n",
    "    df_test_fix_preprocessed[\"T_boxcox_\"+col], _ = stats.boxcox(\n",
    "        df_test_fix_preprocessed[col] + 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_inverse_\"+col] = 1 / (df_train_fix_preprocessed[col] + 1)\n",
    "    df_test_fix_preprocessed[\"T_inverse_\"+col] = 1 / (df_test_fix_preprocessed[col] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "categorical_features_onehot = [\n",
    "    \"Make\",\n",
    "    \"Fuel Type\",\n",
    "]\n",
    "\n",
    "categorical_features_binary = [\n",
    "    \"Vehicle Class\",\n",
    "    \"Transmission\",\n",
    "]\n",
    "\n",
    "df_categorical_one_hot = df_train_fix_preprocessed[categorical_features_onehot].copy()\n",
    "df_categorical_binary = df_train_fix_preprocessed[categorical_features_binary].copy()\n",
    "\n",
    "encoder_onehot = OneHotEncoder(sparse_output=False)\n",
    "encoder_onehot.set_output(transform=\"pandas\")\n",
    "onehot_encoded_data = encoder_onehot.fit_transform(df_categorical_one_hot)\n",
    "# do the same with test data\n",
    "\n",
    "encoder_binary = BinaryEncoder(cols=categorical_features_binary)\n",
    "encoder_binary.set_output(transform=\"pandas\")\n",
    "df_binary = encoder_binary.fit_transform(df_categorical_binary)\n",
    "# do the same with test data\n",
    "\n",
    "\n",
    "onehot_encoded_data_cat = onehot_encoded_data.copy().astype(\"int64\").astype(\"category\")\n",
    "df_binary_cat = df_binary.copy().astype(\"int64\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_log = df_train_fix_preprocessed.filter(regex=\"T_log_\")\n",
    "df_train_sqrt = df_train_fix_preprocessed.filter(regex=\"T_sqrt_\")\n",
    "df_train_boxcox = df_train_fix_preprocessed.filter(regex=\"T_boxcox_\")\n",
    "df_train_inverse = df_train_fix_preprocessed.filter(regex=\"T_inverse_\")\n",
    "\n",
    "df_train_to_model_log = pd.concat(\n",
    "    [df_train_log, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")\n",
    "df_train_to_model_sqrt = pd.concat(\n",
    "    [df_train_sqrt, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")\n",
    "df_train_to_model_boxcox = pd.concat(\n",
    "    [df_train_boxcox, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")\n",
    "df_train_to_model_inverse = pd.concat(\n",
    "    [df_train_inverse, df_binary_cat, onehot_encoded_data_cat], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_log_Fuel Consumption City (L/100Km)</th>\n",
       "      <th>T_log_Fuel Consumption Hwy (L/100Km)</th>\n",
       "      <th>T_log_Fuel Consumption Comb (L/100Km)</th>\n",
       "      <th>T_log_Engine Size(L)</th>\n",
       "      <th>T_log_Cylinders</th>\n",
       "      <th>Vehicle Class_0</th>\n",
       "      <th>Vehicle Class_1</th>\n",
       "      <th>Vehicle Class_2</th>\n",
       "      <th>Vehicle Class_3</th>\n",
       "      <th>Vehicle Class_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Make_MITSU</th>\n",
       "      <th>Make_NIRRAN</th>\n",
       "      <th>Make_RYUNDAI</th>\n",
       "      <th>Make_TOLVO</th>\n",
       "      <th>Make_TOYOTI</th>\n",
       "      <th>Fuel Type_D</th>\n",
       "      <th>Fuel Type_E</th>\n",
       "      <th>Fuel Type_N</th>\n",
       "      <th>Fuel Type_X</th>\n",
       "      <th>Fuel Type_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.265921</td>\n",
       "      <td>1.965713</td>\n",
       "      <td>2.141805</td>\n",
       "      <td>1.504077</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.341801</td>\n",
       "      <td>3.458208</td>\n",
       "      <td>3.395850</td>\n",
       "      <td>1.840550</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993252</td>\n",
       "      <td>1.108563</td>\n",
       "      <td>1.046785</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.793458</td>\n",
       "      <td>2.827314</td>\n",
       "      <td>2.808837</td>\n",
       "      <td>1.117466</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.051640</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.694627</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137136</th>\n",
       "      <td>3.547028</td>\n",
       "      <td>2.163119</td>\n",
       "      <td>3.136643</td>\n",
       "      <td>1.795748</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137137</th>\n",
       "      <td>2.013474</td>\n",
       "      <td>0.625938</td>\n",
       "      <td>1.601643</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137138</th>\n",
       "      <td>1.383791</td>\n",
       "      <td>2.238580</td>\n",
       "      <td>1.858257</td>\n",
       "      <td>1.029619</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137139</th>\n",
       "      <td>2.524127</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>2.001480</td>\n",
       "      <td>1.029619</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137140</th>\n",
       "      <td>1.472472</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.410707</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137141 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        T_log_Fuel Consumption City (L/100Km)  \\\n",
       "0                                    2.265921   \n",
       "1                                    3.341801   \n",
       "2                                    0.993252   \n",
       "3                                    2.793458   \n",
       "4                                    3.051640   \n",
       "...                                       ...   \n",
       "137136                               3.547028   \n",
       "137137                               2.013474   \n",
       "137138                               1.383791   \n",
       "137139                               2.524127   \n",
       "137140                               1.472472   \n",
       "\n",
       "        T_log_Fuel Consumption Hwy (L/100Km)  \\\n",
       "0                                   1.965713   \n",
       "1                                   3.458208   \n",
       "2                                   1.108563   \n",
       "3                                   2.827314   \n",
       "4                                   1.945910   \n",
       "...                                      ...   \n",
       "137136                              2.163119   \n",
       "137137                              0.625938   \n",
       "137138                              2.238580   \n",
       "137139                              0.200004   \n",
       "137140                              1.335001   \n",
       "\n",
       "        T_log_Fuel Consumption Comb (L/100Km)  T_log_Engine Size(L)  \\\n",
       "0                                    2.141805              1.504077   \n",
       "1                                    3.395850              1.840550   \n",
       "2                                    1.046785              1.686399   \n",
       "3                                    2.808837              1.117466   \n",
       "4                                    2.694627              1.386294   \n",
       "...                                       ...                   ...   \n",
       "137136                               3.136643              1.795748   \n",
       "137137                               1.601643              0.916291   \n",
       "137138                               1.858257              1.029619   \n",
       "137139                               2.001480              1.029619   \n",
       "137140                               1.410707              1.252763   \n",
       "\n",
       "        T_log_Cylinders Vehicle Class_0 Vehicle Class_1 Vehicle Class_2  \\\n",
       "0              1.945910               0               0               0   \n",
       "1              2.197225               0               0               0   \n",
       "2              1.945910               0               0               0   \n",
       "3              1.609438               0               0               0   \n",
       "4              1.945910               0               0               1   \n",
       "...                 ...             ...             ...             ...   \n",
       "137136         2.197225               0               0               0   \n",
       "137137         1.609438               0               1               0   \n",
       "137138         1.609438               0               1               0   \n",
       "137139         1.609438               0               0               1   \n",
       "137140         1.609438               0               1               0   \n",
       "\n",
       "       Vehicle Class_3 Vehicle Class_4  ... Make_MITSU Make_NIRRAN  \\\n",
       "0                    0               1  ...          0           0   \n",
       "1                    0               1  ...          0           0   \n",
       "2                    1               0  ...          0           0   \n",
       "3                    1               1  ...          0           0   \n",
       "4                    0               0  ...          0           0   \n",
       "...                ...             ...  ...        ...         ...   \n",
       "137136               1               0  ...          0           0   \n",
       "137137               0               1  ...          0           0   \n",
       "137138               1               0  ...          0           1   \n",
       "137139               0               1  ...          0           0   \n",
       "137140               1               0  ...          0           0   \n",
       "\n",
       "       Make_RYUNDAI Make_TOLVO Make_TOYOTI Fuel Type_D Fuel Type_E  \\\n",
       "0                 0          0           0           0           0   \n",
       "1                 0          0           0           0           1   \n",
       "2                 0          0           0           0           0   \n",
       "3                 0          0           0           0           0   \n",
       "4                 0          0           0           0           0   \n",
       "...             ...        ...         ...         ...         ...   \n",
       "137136            0          0           0           0           0   \n",
       "137137            0          0           0           0           0   \n",
       "137138            0          0           0           0           0   \n",
       "137139            0          0           1           0           0   \n",
       "137140            0          0           0           0           0   \n",
       "\n",
       "       Fuel Type_N Fuel Type_X Fuel Type_Z  \n",
       "0                0           1           0  \n",
       "1                0           0           0  \n",
       "2                0           0           1  \n",
       "3                0           1           0  \n",
       "4                0           0           1  \n",
       "...            ...         ...         ...  \n",
       "137136           0           0           1  \n",
       "137137           0           1           0  \n",
       "137138           0           1           0  \n",
       "137139           0           1           0  \n",
       "137140           0           1           0  \n",
       "\n",
       "[137141 rows x 41 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_to_model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 137141 entries, 0 to 137140\n",
      "Data columns (total 41 columns):\n",
      " #   Column                                 Non-Null Count   Dtype   \n",
      "---  ------                                 --------------   -----   \n",
      " 0   T_log_Fuel Consumption City (L/100Km)  137141 non-null  float64 \n",
      " 1   T_log_Fuel Consumption Hwy (L/100Km)   137141 non-null  float64 \n",
      " 2   T_log_Fuel Consumption Comb (L/100Km)  137141 non-null  float64 \n",
      " 3   T_log_Engine Size(L)                   137141 non-null  float64 \n",
      " 4   T_log_Cylinders                        137141 non-null  float64 \n",
      " 5   Vehicle Class_0                        137141 non-null  category\n",
      " 6   Vehicle Class_1                        137141 non-null  category\n",
      " 7   Vehicle Class_2                        137141 non-null  category\n",
      " 8   Vehicle Class_3                        137141 non-null  category\n",
      " 9   Vehicle Class_4                        137141 non-null  category\n",
      " 10  Transmission_0                         137141 non-null  category\n",
      " 11  Transmission_1                         137141 non-null  category\n",
      " 12  Transmission_2                         137141 non-null  category\n",
      " 13  Transmission_3                         137141 non-null  category\n",
      " 14  Transmission_4                         137141 non-null  category\n",
      " 15  Make_ASURA                             137141 non-null  category\n",
      " 16  Make_BARUSU                            137141 non-null  category\n",
      " 17  Make_BMV                               137141 non-null  category\n",
      " 18  Make_CADILUXE                          137141 non-null  category\n",
      " 19  Make_CHEVO                             137141 non-null  category\n",
      " 20  Make_DOGE                              137141 non-null  category\n",
      " 21  Make_FIAR                              137141 non-null  category\n",
      " 22  Make_FOLD                              137141 non-null  category\n",
      " 23  Make_FOLKSWA                           137141 non-null  category\n",
      " 24  Make_GONDA                             137141 non-null  category\n",
      " 25  Make_JIPU                              137141 non-null  category\n",
      " 26  Make_KIO                               137141 non-null  category\n",
      " 27  Make_LAMBOGI                           137141 non-null  category\n",
      " 28  Make_LAND CRAWLER                      137141 non-null  category\n",
      " 29  Make_LECUS                             137141 non-null  category\n",
      " 30  Make_MATSUDA                           137141 non-null  category\n",
      " 31  Make_MITSU                             137141 non-null  category\n",
      " 32  Make_NIRRAN                            137141 non-null  category\n",
      " 33  Make_RYUNDAI                           137141 non-null  category\n",
      " 34  Make_TOLVO                             137141 non-null  category\n",
      " 35  Make_TOYOTI                            137141 non-null  category\n",
      " 36  Fuel Type_D                            137141 non-null  category\n",
      " 37  Fuel Type_E                            137141 non-null  category\n",
      " 38  Fuel Type_N                            137141 non-null  category\n",
      " 39  Fuel Type_X                            137141 non-null  category\n",
      " 40  Fuel Type_Z                            137141 non-null  category\n",
      "dtypes: category(36), float64(5)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_train_to_model_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost\n",
    "- LGBM\n",
    "- DNN (NOT YET)\n",
    "- ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model_svr = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_dt = DecisionTreeRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_xgb = XGBRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model_lgbm = lgb.LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sesar\\Documents\\_PROJECTS\\bebass\\venv31011\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sesar\\Documents\\_PROJECTS\\bebass\\venv31011\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\sesar\\Documents\\_PROJECTS\\bebass\\venv31011\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assuming you have training data X_train, y_train\n",
    "model_dnn = Sequential()\n",
    "model_dnn.add(\n",
    "    Dense(256, input_dim=df_train_to_model_log.shape[1], activation=\"relu\")\n",
    ")  # Input layer\n",
    "model_dnn.add(Dense(256, activation=\"relu\"))  # Hidden layer 1\n",
    "model_dnn.add(Dense(256, activation=\"relu\"))  # Hidden layer 2\n",
    "model_dnn.add(Dense(1))  # Output layer\n",
    "\n",
    "model_dnn.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "model_ensemble = StackingRegressor(estimators=[(\"xgb\", model_xgb), (\"lgbm\", model_lgbm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 1, Mean RMSE: 46.9422, Mean Training time: 0.9191 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 2, Mean RMSE: 46.9422, Mean Training time: 0.9586 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 3, Mean RMSE: 46.9206, Mean Training time: 0.8357 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 4, Mean RMSE: 46.9414, Mean Training time: 0.7649 seconds\n",
      "Model: XGBRegressor, Dataset: 1, Mean RMSE: 46.5985, Mean Training time: 0.9005 seconds\n",
      "Model: XGBRegressor, Dataset: 2, Mean RMSE: 46.5669, Mean Training time: 0.9239 seconds\n",
      "Model: XGBRegressor, Dataset: 3, Mean RMSE: 46.5669, Mean Training time: 0.9059 seconds\n",
      "Model: XGBRegressor, Dataset: 4, Mean RMSE: 46.6655, Mean Training time: 1.0617 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 1, Mean RMSE: 46.2681, Mean Training time: 9.5662 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 2, Mean RMSE: 46.2498, Mean Training time: 10.1799 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 3, Mean RMSE: 46.2400, Mean Training time: 9.0574 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1082\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 4, Mean RMSE: 46.2983, Mean Training time: 7.8942 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'models' is a list of your models\n",
    "models = [model_lgbm, model_xgb, model_ensemble]\n",
    "\n",
    "# Create a list of your datasets\n",
    "datasets = [\n",
    "    df_train_to_model_log,\n",
    "    df_train_to_model_sqrt,\n",
    "    df_train_to_model_boxcox,\n",
    "    df_train_to_model_inverse,\n",
    "]\n",
    "\n",
    "y = df_target\n",
    "\n",
    "# Initialize a dictionary to hold your results\n",
    "results = {}\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Loop over your models\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    results[model_name] = {}\n",
    "\n",
    "    # Loop over your datasets\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        results[model_name][f\"dataset_{i+1}\"] = {\n",
    "            \"rmse\": [],\n",
    "            \"training_time\": [],\n",
    "        }\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, test_index in kf.split(dataset):\n",
    "            X_train, X_test = dataset.iloc[train_index], dataset.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Create a StandardScaler object\n",
    "            # scaler = StandardScaler()\n",
    "            scaler = MinMaxScaler()\n",
    "\n",
    "            numerical_column = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "            non_numerical_columns = [\n",
    "                col for col in X_train.columns if col not in numerical_column\n",
    "            ]\n",
    "            for col in non_numerical_columns:\n",
    "                X_train.loc[:, col] = X_train.loc[:, col].astype(\"int64\")\n",
    "                X_test.loc[:, col] = X_test.loc[:, col].astype(\"int64\")\n",
    "\n",
    "            # Normalize the data\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # Start the timer\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # End the timer\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Calculate the training time\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            # Store the results\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"].append(rmse)\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"].append(training_time)\n",
    "\n",
    "        # Calculate the mean RMSE and training time\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"rmse\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"]\n",
    "        )\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"training_time\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"]\n",
    "        )\n",
    "\n",
    "        # Print the process\n",
    "        print(\n",
    "            f\"Model: {model_name}, Dataset: {i+1}, Mean RMSE: {results[model_name][f'dataset_{i+1}']['rmse']:.4f}, Mean Training time: {results[model_name][f'dataset_{i+1}']['training_time']:.4f} seconds\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LGBMRegressor': {'dataset_1': {'rmse': 46.94216853734896,\n",
       "   'training_time': 0.9190744400024414},\n",
       "  'dataset_2': {'rmse': 46.94216853734896,\n",
       "   'training_time': 0.9586390495300293},\n",
       "  'dataset_3': {'rmse': 46.920581073277916,\n",
       "   'training_time': 0.8357211589813233},\n",
       "  'dataset_4': {'rmse': 46.941424197500766,\n",
       "   'training_time': 0.7649320602416992}},\n",
       " 'XGBRegressor': {'dataset_1': {'rmse': 46.59845121757011,\n",
       "   'training_time': 0.9004532814025878},\n",
       "  'dataset_2': {'rmse': 46.56686175055463,\n",
       "   'training_time': 0.9238646030426025},\n",
       "  'dataset_3': {'rmse': 46.56686175055463,\n",
       "   'training_time': 0.9058956623077392},\n",
       "  'dataset_4': {'rmse': 46.66546281768829,\n",
       "   'training_time': 1.061687994003296}},\n",
       " 'StackingRegressor': {'dataset_1': {'rmse': 46.2681058791802,\n",
       "   'training_time': 9.566197443008424},\n",
       "  'dataset_2': {'rmse': 46.24983122896833, 'training_time': 10.17987027168274},\n",
       "  'dataset_3': {'rmse': 46.239973943477665,\n",
       "   'training_time': 9.057394886016846},\n",
       "  'dataset_4': {'rmse': 46.298291840643536,\n",
       "   'training_time': 7.894232892990113}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.942169</td>\n",
       "      <td>0.919074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.942169</td>\n",
       "      <td>0.958639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.920581</td>\n",
       "      <td>0.835721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.941424</td>\n",
       "      <td>0.764932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.598451</td>\n",
       "      <td>0.900453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.566862</td>\n",
       "      <td>0.923865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.566862</td>\n",
       "      <td>0.905896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.665463</td>\n",
       "      <td>1.061688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.268106</td>\n",
       "      <td>9.566197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.249831</td>\n",
       "      <td>10.179870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.239974</td>\n",
       "      <td>9.057395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.298292</td>\n",
       "      <td>7.894233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Dataset       RMSE  Training Time\n",
       "0       LGBMRegressor  dataset_1  46.942169       0.919074\n",
       "1       LGBMRegressor  dataset_2  46.942169       0.958639\n",
       "2       LGBMRegressor  dataset_3  46.920581       0.835721\n",
       "3       LGBMRegressor  dataset_4  46.941424       0.764932\n",
       "4        XGBRegressor  dataset_1  46.598451       0.900453\n",
       "5        XGBRegressor  dataset_2  46.566862       0.923865\n",
       "6        XGBRegressor  dataset_3  46.566862       0.905896\n",
       "7        XGBRegressor  dataset_4  46.665463       1.061688\n",
       "8   StackingRegressor  dataset_1  46.268106       9.566197\n",
       "9   StackingRegressor  dataset_2  46.249831      10.179870\n",
       "10  StackingRegressor  dataset_3  46.239974       9.057395\n",
       "11  StackingRegressor  dataset_4  46.298292       7.894233"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the nested dictionary into a pandas DataFrame\n",
    "df_results = pd.concat({k: pd.DataFrame(v).T for k, v in results.items()}, axis=0)\n",
    "\n",
    "# Reset the index and rename the columns for a cleaner look\n",
    "df_results.reset_index(inplace=True)\n",
    "df_results.columns = [\"Model\", \"Dataset\", \"RMSE\", \"Training Time\"]\n",
    "\n",
    "df_results.to_csv(\"results_4.csv\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.239974</td>\n",
       "      <td>9.057395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.249831</td>\n",
       "      <td>10.179870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.268106</td>\n",
       "      <td>9.566197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.298292</td>\n",
       "      <td>7.894233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.566862</td>\n",
       "      <td>0.923865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.566862</td>\n",
       "      <td>0.905896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.598451</td>\n",
       "      <td>0.900453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.665463</td>\n",
       "      <td>1.061688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.920581</td>\n",
       "      <td>0.835721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.941424</td>\n",
       "      <td>0.764932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.942169</td>\n",
       "      <td>0.919074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.942169</td>\n",
       "      <td>0.958639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Dataset       RMSE  Training Time\n",
       "10  StackingRegressor  dataset_3  46.239974       9.057395\n",
       "9   StackingRegressor  dataset_2  46.249831      10.179870\n",
       "8   StackingRegressor  dataset_1  46.268106       9.566197\n",
       "11  StackingRegressor  dataset_4  46.298292       7.894233\n",
       "5        XGBRegressor  dataset_2  46.566862       0.923865\n",
       "6        XGBRegressor  dataset_3  46.566862       0.905896\n",
       "4        XGBRegressor  dataset_1  46.598451       0.900453\n",
       "7        XGBRegressor  dataset_4  46.665463       1.061688\n",
       "2       LGBMRegressor  dataset_3  46.920581       0.835721\n",
       "3       LGBMRegressor  dataset_4  46.941424       0.764932\n",
       "0       LGBMRegressor  dataset_1  46.942169       0.919074\n",
       "1       LGBMRegressor  dataset_2  46.942169       0.958639"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df_results.sort_values(by=\"RMSE\", ascending=True)\n",
    "df_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv31011",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
