{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"./dataset/train_preprocessed_imputed_preprocessed.csv\")\n",
    "# df_target = df_train.pop(\"CO2 Emissions(g/km)\")\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(\"./dataset/test_preprocessed.csv\")\n",
    "# df_test.rename(\n",
    "#     columns={\n",
    "#         \"Fuel Consumption City\": \"Fuel Consumption City (L/100Km)\",\n",
    "#         \"Fuel Consumption Hwy\": \"Fuel Consumption Hwy (L/100Km)\",\n",
    "#         \"Fuel Consumption Comb\": \"Fuel Consumption Comb (L/100Km)\",\n",
    "#     },\n",
    "#     inplace=True,\n",
    "# )\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = pd.concat([df_train, df_test])\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fuelconsumption = df_all[\n",
    "#     [\n",
    "#         \"Fuel Consumption City (L/100Km)\",\n",
    "#         \"Fuel Consumption Hwy (L/100Km)\",\n",
    "#         \"Fuel Consumption Comb (L/100Km)\",\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# df_enginecylinders = df_all[\n",
    "#     # [\"Engine Size(L)\", \"Cylinders\", \"CO2 Emissions(g/km)\", \"Make\", \"Vehicle Class\"] # with category features\n",
    "#     [\"Engine Size(L)\", \"Cylinders\"]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "\n",
    "# imp = IterativeImputer(random_state=42)\n",
    "# imp.set_output(transform=\"pandas\")\n",
    "# imp.fit(df_fuelconsumption)\n",
    "# df_fuelconsumption_imputed = imp.transform(df_fuelconsumption)\n",
    "\n",
    "# imp = IterativeImputer(random_state=42)\n",
    "# imp.set_output(transform=\"pandas\")\n",
    "# imp.fit(df_enginecylinders)\n",
    "# df_enginecylinders_imputed = imp.transform(df_enginecylinders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add data to df_all_fix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # there were data < 0, so we need to replace it with 0\n",
    "\n",
    "# df_numerical_imputed = pd.concat(\n",
    "#     [df_fuelconsumption_imputed, df_enginecylinders_imputed], axis=1\n",
    "# )\n",
    "# df_numerical_imputed = df_numerical_imputed.clip(lower=0)\n",
    "\n",
    "# df_numerical_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix1 = df_all.drop(df_numerical_imputed.columns.tolist(), axis=1)\n",
    "# df_fix1 = pd.concat([df_fix1, df_numerical_imputed], axis=1)\n",
    "# df_fix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_categorical_imputed = df_fix1[\n",
    "#     [\n",
    "#         \"Make\",\n",
    "#         \"Vehicle Class\",\n",
    "#         \"Transmission\",\n",
    "#         \"Fuel Type\",\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#         \"Engine Size(L)\",\n",
    "#         \"Cylinders\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# for col in df_categorical_imputed.columns:\n",
    "#     if df_categorical_imputed[col].dtype == \"object\":\n",
    "#         df_categorical_imputed[col] = df_categorical_imputed[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import miceforest as mf\n",
    "\n",
    "# # might consider \"UserWarning: [Transmission,Fuel Type] have very rare categories, it is a good idea to group these, or set the min_data_in_leaf parameter to prevent lightgbm from outputting 0.0 probabilities.\"\n",
    "\n",
    "# kds = mf.ImputationKernel(\n",
    "#     df_categorical_imputed, save_all_iterations=True, random_state=42\n",
    "# )\n",
    "# kds.mice(10)\n",
    "# df_categorical_imputed = kds.complete_data()\n",
    "\n",
    "# df_categorical_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_categorical_impupted_fix = df_categorical_imputed.copy()\n",
    "# df_categorical_impupted_fix = df_categorical_impupted_fix.drop(\n",
    "#     [\n",
    "#         # \"CO2 Emissions(g/km)\",\n",
    "#         \"Engine Size(L)\",\n",
    "#         \"Cylinders\",\n",
    "#     ],\n",
    "#     axis=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix2 = df_fix1.drop(df_categorical_impupted_fix.columns.tolist(), axis=1)\n",
    "# df_fix2 = pd.concat([df_fix2, df_categorical_impupted_fix], axis=1)\n",
    "# df_fix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fix3 = df_fix2.copy()\n",
    "# df_fix3.reset_index(drop=True, inplace=True)\n",
    "# df_fix3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix = df_fix3.iloc[:df_train.shape[0], :]\n",
    "# df_train_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_fix = df_fix3.iloc[df_train.shape[0] :, :]\n",
    "# df_test_fix.reset_index(drop=True, inplace=True)\n",
    "# df_test_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix = pd.concat([df_train_fix, df_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_fix.to_csv(\"./dataset/train_fix.csv\", index=False)\n",
    "# df_test_fix.to_csv(\"./dataset/test_fix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dython.nominal import associations\n",
    "\n",
    "# associations(df_train_fix)\n",
    "# associations(df_test_fix)\n",
    "# associations(df_fix3)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fix = pd.read_csv(\"./dataset/train_fix.csv\")\n",
    "df_test_fix = pd.read_csv(\"./dataset/test_fix.csv\")\n",
    "df_test_id = df_test_fix['Id']\n",
    "df_target = df_train_fix.pop(\"CO2 Emissions(g/km)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Value:\n",
    "- Fuel Consumption City (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Fuel Consumption Hwy (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Fuel Consumption Comb (L/100Km) -> log, sqrt, boxcox, inverse\n",
    "- Engine Size(L) -> log, sqrt, boxcox, inverse\n",
    "- Cylinders -> log, sqrt, boxcox, inverse\n",
    "\n",
    "Categorical Value:\n",
    "- Make -> one-hot\n",
    "- Vehicle Class -> binary\n",
    "- Transmission -> binary \n",
    "- Fuel Type -> one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fix_preprocessed = df_train_fix.copy()\n",
    "df_test_fix_preprocessed = df_test_fix.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Fuel Consumption City (L/100Km)</th>\n",
       "      <th>Fuel Consumption Hwy (L/100Km)</th>\n",
       "      <th>Fuel Consumption Comb (L/100Km)</th>\n",
       "      <th>Engine Size(L)</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Make</th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Fuel Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.640000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>7.514791</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>FOLD</td>\n",
       "      <td>PICKUP TRUCK - STANDARD</td>\n",
       "      <td>A6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27.270000</td>\n",
       "      <td>30.760000</td>\n",
       "      <td>28.840000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CHEVO</td>\n",
       "      <td>PICKUP TRUCK - STANDARD</td>\n",
       "      <td>A6</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>1.848477</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BMV</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>M6</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15.337423</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>15.590609</td>\n",
       "      <td>2.057097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>KIO</td>\n",
       "      <td>SUV - SMALL</td>\n",
       "      <td>AS6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.150000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BARUSU</td>\n",
       "      <td>MINICOMPACT</td>\n",
       "      <td>AS6</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137136</th>\n",
       "      <td>137137</td>\n",
       "      <td>33.710000</td>\n",
       "      <td>7.698229</td>\n",
       "      <td>22.026432</td>\n",
       "      <td>5.023977</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BMV</td>\n",
       "      <td>SUBCOMPACT</td>\n",
       "      <td>AS8</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137137</th>\n",
       "      <td>137138</td>\n",
       "      <td>6.489293</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>3.961175</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GONDA</td>\n",
       "      <td>STATION WAGON - SMALL</td>\n",
       "      <td>M6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137138</th>\n",
       "      <td>137139</td>\n",
       "      <td>2.990000</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>5.412550</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NIRRAN</td>\n",
       "      <td>MID-SIZE</td>\n",
       "      <td>AV</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137139</th>\n",
       "      <td>137140</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>0.221408</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TOYOTI</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>AV</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137140</th>\n",
       "      <td>137141</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.098853</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BARUSU</td>\n",
       "      <td>MID-SIZE</td>\n",
       "      <td>AV6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137141 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Fuel Consumption City (L/100Km)  \\\n",
       "0            1                         8.640000   \n",
       "1            2                        27.270000   \n",
       "2            3                         1.700000   \n",
       "3            4                        15.337423   \n",
       "4            5                        20.150000   \n",
       "...        ...                              ...   \n",
       "137136  137137                        33.710000   \n",
       "137137  137138                         6.489293   \n",
       "137138  137139                         2.990000   \n",
       "137139  137140                        11.480000   \n",
       "137140  137141                         3.360000   \n",
       "\n",
       "        Fuel Consumption Hwy (L/100Km)  Fuel Consumption Comb (L/100Km)  \\\n",
       "0                             6.140000                         7.514791   \n",
       "1                            30.760000                        28.840000   \n",
       "2                             2.030000                         1.848477   \n",
       "3                            15.900000                        15.590609   \n",
       "4                             6.000000                        13.800000   \n",
       "...                                ...                              ...   \n",
       "137136                        7.698229                        22.026432   \n",
       "137137                        0.870000                         3.961175   \n",
       "137138                        8.380000                         5.412550   \n",
       "137139                        0.221408                         6.400000   \n",
       "137140                        2.800000                         3.098853   \n",
       "\n",
       "        Engine Size(L)  Cylinders    Make            Vehicle Class  \\\n",
       "0             3.500000        6.0    FOLD  PICKUP TRUCK - STANDARD   \n",
       "1             5.300000        8.0   CHEVO  PICKUP TRUCK - STANDARD   \n",
       "2             4.400000        6.0     BMV               SUBCOMPACT   \n",
       "3             2.057097        4.0     KIO              SUV - SMALL   \n",
       "4             3.000000        6.0  BARUSU              MINICOMPACT   \n",
       "...                ...        ...     ...                      ...   \n",
       "137136        5.023977        8.0     BMV               SUBCOMPACT   \n",
       "137137        1.500000        4.0   GONDA    STATION WAGON - SMALL   \n",
       "137138        1.800000        4.0  NIRRAN                 MID-SIZE   \n",
       "137139        1.800000        4.0  TOYOTI                  COMPACT   \n",
       "137140        2.500000        4.0  BARUSU                 MID-SIZE   \n",
       "\n",
       "       Transmission Fuel Type  \n",
       "0                A6         X  \n",
       "1                A6         E  \n",
       "2                M6         Z  \n",
       "3               AS6         X  \n",
       "4               AS6         Z  \n",
       "...             ...       ...  \n",
       "137136          AS8         Z  \n",
       "137137           M6         X  \n",
       "137138           AV         X  \n",
       "137139           AV         X  \n",
       "137140          AV6         X  \n",
       "\n",
       "[137141 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fix_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PowerTransformer <- MIGHT USE THIS\n",
    "\n",
    "column_to_transform = [\n",
    "    \"Fuel Consumption City (L/100Km)\",\n",
    "    \"Fuel Consumption Hwy (L/100Km)\",\n",
    "    \"Fuel Consumption Comb (L/100Km)\",\n",
    "    \"Engine Size(L)\",\n",
    "    \"Cylinders\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_log_\"+col] = np.log(df_train_fix_preprocessed[col] + 1)\n",
    "    df_test_fix_preprocessed[\"T_log_\"+col] = np.log(df_test_fix_preprocessed[col] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_sqrt_\"+col] = np.sqrt(df_train_fix_preprocessed[col])\n",
    "    df_test_fix_preprocessed[\"T_sqrt_\"+col] = np.sqrt(df_test_fix_preprocessed[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_boxcox_\"+col], _ = stats.boxcox(\n",
    "        df_train_fix_preprocessed[col] + 1\n",
    "    )\n",
    "    df_test_fix_preprocessed[\"T_boxcox_\"+col], _ = stats.boxcox(\n",
    "        df_test_fix_preprocessed[col] + 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_to_transform:\n",
    "    df_train_fix_preprocessed[\"T_inverse_\"+col] = 1 / (df_train_fix_preprocessed[col] + 1)\n",
    "    df_test_fix_preprocessed[\"T_inverse_\"+col] = 1 / (df_test_fix_preprocessed[col] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "categorical_features_onehot = [\n",
    "    \"Make\",\n",
    "    \"Fuel Type\",\n",
    "]\n",
    "\n",
    "categorical_features_binary = [\n",
    "    \"Vehicle Class\",\n",
    "    \"Transmission\",\n",
    "]\n",
    "\n",
    "df_train_categorical_one_hot = df_train_fix_preprocessed[\n",
    "    categorical_features_onehot\n",
    "].copy()\n",
    "df_train_categorical_binary = df_train_fix_preprocessed[\n",
    "    categorical_features_binary\n",
    "].copy()\n",
    "\n",
    "df_test_categorical_one_hot = df_test_fix_preprocessed[\n",
    "    categorical_features_onehot\n",
    "].copy()\n",
    "df_test_categorical_binary = df_test_fix_preprocessed[\n",
    "    categorical_features_binary\n",
    "].copy()\n",
    "\n",
    "\n",
    "encoder_onehot = OneHotEncoder(sparse_output=False)\n",
    "encoder_onehot.set_output(transform=\"pandas\")\n",
    "train_onehot_encoded_data = encoder_onehot.fit_transform(df_train_categorical_one_hot)\n",
    "\n",
    "# do the same with test data\n",
    "test_onehot_encoded_data = encoder_onehot.transform(df_test_categorical_one_hot)\n",
    "\n",
    "encoder_binary = BinaryEncoder(cols=categorical_features_binary)\n",
    "encoder_binary.set_output(transform=\"pandas\")\n",
    "train_df_binary = encoder_binary.fit_transform(df_train_categorical_binary)\n",
    "\n",
    "# do the same with test data\n",
    "test_df_binary = encoder_binary.transform(df_test_categorical_binary)\n",
    "\n",
    "\n",
    "onehot_encoded_data_cat_train = (\n",
    "    train_onehot_encoded_data.copy().astype(\"int64\").astype(\"category\")\n",
    ")\n",
    "df_binary_cat_train = train_df_binary.copy().astype(\"int64\").astype(\"category\")\n",
    "\n",
    "onehot_encoded_data_cat_test = (\n",
    "    test_onehot_encoded_data.copy().astype(\"int64\").astype(\"category\")\n",
    ")\n",
    "df_binary_cat_test = test_df_binary.copy().astype(\"int64\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_log = df_train_fix_preprocessed.filter(regex=\"T_log_\")\n",
    "df_train_sqrt = df_train_fix_preprocessed.filter(regex=\"T_sqrt_\")\n",
    "df_train_boxcox = df_train_fix_preprocessed.filter(regex=\"T_boxcox_\")\n",
    "df_train_inverse = df_train_fix_preprocessed.filter(regex=\"T_inverse_\")\n",
    "\n",
    "df_train_to_model_log = pd.concat(\n",
    "    [df_train_log, df_binary_cat_train, onehot_encoded_data_cat_train], axis=1\n",
    ")\n",
    "df_train_to_model_sqrt = pd.concat(\n",
    "    [df_train_sqrt, df_binary_cat_train, onehot_encoded_data_cat_train], axis=1\n",
    ")\n",
    "df_train_to_model_boxcox = pd.concat(\n",
    "    [df_train_boxcox, df_binary_cat_train, onehot_encoded_data_cat_train], axis=1\n",
    ")\n",
    "df_train_to_model_inverse = pd.concat(\n",
    "    [df_train_inverse, df_binary_cat_train, onehot_encoded_data_cat_train], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_log = df_test_fix_preprocessed.filter(regex=\"T_log_\")\n",
    "df_test_sqrt = df_test_fix_preprocessed.filter(regex=\"T_sqrt_\")\n",
    "df_test_boxcox = df_test_fix_preprocessed.filter(regex=\"T_boxcox_\")\n",
    "df_test_inverse = df_test_fix_preprocessed.filter(regex=\"T_inverse_\")\n",
    "\n",
    "df_test_to_model_log = pd.concat(\n",
    "    [df_test_log, df_binary_cat_test, onehot_encoded_data_cat_test], axis=1\n",
    ")\n",
    "df_test_to_model_sqrt = pd.concat(\n",
    "    [df_test_sqrt, df_binary_cat_test, onehot_encoded_data_cat_test], axis=1\n",
    ")\n",
    "df_test_to_model_boxcox = pd.concat(\n",
    "    [df_test_boxcox, df_binary_cat_test, onehot_encoded_data_cat_test], axis=1\n",
    ")\n",
    "df_test_to_model_inverse = pd.concat(\n",
    "    [df_test_inverse, df_binary_cat_test, onehot_encoded_data_cat_test], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_log_Fuel Consumption City (L/100Km)</th>\n",
       "      <th>T_log_Fuel Consumption Hwy (L/100Km)</th>\n",
       "      <th>T_log_Fuel Consumption Comb (L/100Km)</th>\n",
       "      <th>T_log_Engine Size(L)</th>\n",
       "      <th>T_log_Cylinders</th>\n",
       "      <th>Vehicle Class_0</th>\n",
       "      <th>Vehicle Class_1</th>\n",
       "      <th>Vehicle Class_2</th>\n",
       "      <th>Vehicle Class_3</th>\n",
       "      <th>Vehicle Class_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Make_MITSU</th>\n",
       "      <th>Make_NIRRAN</th>\n",
       "      <th>Make_RYUNDAI</th>\n",
       "      <th>Make_TOLVO</th>\n",
       "      <th>Make_TOYOTI</th>\n",
       "      <th>Fuel Type_D</th>\n",
       "      <th>Fuel Type_E</th>\n",
       "      <th>Fuel Type_N</th>\n",
       "      <th>Fuel Type_X</th>\n",
       "      <th>Fuel Type_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.810908</td>\n",
       "      <td>1.018847</td>\n",
       "      <td>2.341186</td>\n",
       "      <td>1.526056</td>\n",
       "      <td>1.949305</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.096030</td>\n",
       "      <td>2.733068</td>\n",
       "      <td>2.948807</td>\n",
       "      <td>1.547563</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.238738</td>\n",
       "      <td>2.423984</td>\n",
       "      <td>2.950074</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.291777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.879198</td>\n",
       "      <td>2.827210</td>\n",
       "      <td>2.857619</td>\n",
       "      <td>1.722767</td>\n",
       "      <td>2.106460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.752579</td>\n",
       "      <td>3.003267</td>\n",
       "      <td>3.481855</td>\n",
       "      <td>1.686399</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58771</th>\n",
       "      <td>2.962943</td>\n",
       "      <td>3.086487</td>\n",
       "      <td>3.020425</td>\n",
       "      <td>1.458615</td>\n",
       "      <td>1.896902</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58772</th>\n",
       "      <td>1.972671</td>\n",
       "      <td>2.028113</td>\n",
       "      <td>1.997891</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58773</th>\n",
       "      <td>2.740372</td>\n",
       "      <td>2.485041</td>\n",
       "      <td>2.633605</td>\n",
       "      <td>1.504077</td>\n",
       "      <td>1.932141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58774</th>\n",
       "      <td>2.243002</td>\n",
       "      <td>1.721701</td>\n",
       "      <td>2.041248</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>3.038826</td>\n",
       "      <td>0.170816</td>\n",
       "      <td>2.485981</td>\n",
       "      <td>1.504077</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58776 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       T_log_Fuel Consumption City (L/100Km)  \\\n",
       "0                                   2.810908   \n",
       "1                                   3.096030   \n",
       "2                                   3.238738   \n",
       "3                                   2.879198   \n",
       "4                                   3.752579   \n",
       "...                                      ...   \n",
       "58771                               2.962943   \n",
       "58772                               1.972671   \n",
       "58773                               2.740372   \n",
       "58774                               2.243002   \n",
       "58775                               3.038826   \n",
       "\n",
       "       T_log_Fuel Consumption Hwy (L/100Km)  \\\n",
       "0                                  1.018847   \n",
       "1                                  2.733068   \n",
       "2                                  2.423984   \n",
       "3                                  2.827210   \n",
       "4                                  3.003267   \n",
       "...                                     ...   \n",
       "58771                              3.086487   \n",
       "58772                              2.028113   \n",
       "58773                              2.485041   \n",
       "58774                              1.721701   \n",
       "58775                              0.170816   \n",
       "\n",
       "       T_log_Fuel Consumption Comb (L/100Km)  T_log_Engine Size(L)  \\\n",
       "0                                   2.341186              1.526056   \n",
       "1                                   2.948807              1.547563   \n",
       "2                                   2.950074              1.945910   \n",
       "3                                   2.857619              1.722767   \n",
       "4                                   3.481855              1.686399   \n",
       "...                                      ...                   ...   \n",
       "58771                               3.020425              1.458615   \n",
       "58772                               1.997891              0.955511   \n",
       "58773                               2.633605              1.504077   \n",
       "58774                               2.041248              1.791759   \n",
       "58775                               2.485981              1.504077   \n",
       "\n",
       "       T_log_Cylinders Vehicle Class_0 Vehicle Class_1 Vehicle Class_2  \\\n",
       "0             1.949305               0               1               0   \n",
       "1             1.945910               0               1               1   \n",
       "2             2.291777               0               0               0   \n",
       "3             2.106460               0               1               0   \n",
       "4             2.197225               0               0               1   \n",
       "...                ...             ...             ...             ...   \n",
       "58771         1.896902               0               0               0   \n",
       "58772         1.609438               0               0               0   \n",
       "58773         1.932141               0               0               1   \n",
       "58774         2.197225               0               0               0   \n",
       "58775         1.945910               0               0               0   \n",
       "\n",
       "      Vehicle Class_3 Vehicle Class_4  ... Make_MITSU Make_NIRRAN  \\\n",
       "0                   1               0  ...          0           0   \n",
       "1                   1               1  ...          0           0   \n",
       "2                   1               1  ...          1           0   \n",
       "3                   1               0  ...          0           0   \n",
       "4                   1               1  ...          0           0   \n",
       "...               ...             ...  ...        ...         ...   \n",
       "58771               1               1  ...          0           0   \n",
       "58772               0               1  ...          0           0   \n",
       "58773               1               1  ...          0           0   \n",
       "58774               0               1  ...          0           0   \n",
       "58775               1               1  ...          0           0   \n",
       "\n",
       "      Make_RYUNDAI Make_TOLVO Make_TOYOTI Fuel Type_D Fuel Type_E Fuel Type_N  \\\n",
       "0                0          0           0           0           0           0   \n",
       "1                0          0           0           0           0           0   \n",
       "2                0          0           0           0           0           0   \n",
       "3                0          0           0           0           0           0   \n",
       "4                0          0           0           0           0           0   \n",
       "...            ...        ...         ...         ...         ...         ...   \n",
       "58771            0          0           0           0           0           0   \n",
       "58772            0          0           0           0           0           0   \n",
       "58773            0          0           0           0           0           0   \n",
       "58774            0          0           0           0           0           0   \n",
       "58775            0          0           0           0           0           0   \n",
       "\n",
       "      Fuel Type_X Fuel Type_Z  \n",
       "0               1           0  \n",
       "1               1           0  \n",
       "2               1           0  \n",
       "3               0           1  \n",
       "4               0           1  \n",
       "...           ...         ...  \n",
       "58771           1           0  \n",
       "58772           1           0  \n",
       "58773           1           0  \n",
       "58774           1           0  \n",
       "58775           0           1  \n",
       "\n",
       "[58776 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_to_model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58776 entries, 0 to 58775\n",
      "Data columns (total 41 columns):\n",
      " #   Column                                 Non-Null Count  Dtype   \n",
      "---  ------                                 --------------  -----   \n",
      " 0   T_log_Fuel Consumption City (L/100Km)  58776 non-null  float64 \n",
      " 1   T_log_Fuel Consumption Hwy (L/100Km)   58776 non-null  float64 \n",
      " 2   T_log_Fuel Consumption Comb (L/100Km)  58776 non-null  float64 \n",
      " 3   T_log_Engine Size(L)                   58776 non-null  float64 \n",
      " 4   T_log_Cylinders                        58776 non-null  float64 \n",
      " 5   Vehicle Class_0                        58776 non-null  category\n",
      " 6   Vehicle Class_1                        58776 non-null  category\n",
      " 7   Vehicle Class_2                        58776 non-null  category\n",
      " 8   Vehicle Class_3                        58776 non-null  category\n",
      " 9   Vehicle Class_4                        58776 non-null  category\n",
      " 10  Transmission_0                         58776 non-null  category\n",
      " 11  Transmission_1                         58776 non-null  category\n",
      " 12  Transmission_2                         58776 non-null  category\n",
      " 13  Transmission_3                         58776 non-null  category\n",
      " 14  Transmission_4                         58776 non-null  category\n",
      " 15  Make_ASURA                             58776 non-null  category\n",
      " 16  Make_BARUSU                            58776 non-null  category\n",
      " 17  Make_BMV                               58776 non-null  category\n",
      " 18  Make_CADILUXE                          58776 non-null  category\n",
      " 19  Make_CHEVO                             58776 non-null  category\n",
      " 20  Make_DOGE                              58776 non-null  category\n",
      " 21  Make_FIAR                              58776 non-null  category\n",
      " 22  Make_FOLD                              58776 non-null  category\n",
      " 23  Make_FOLKSWA                           58776 non-null  category\n",
      " 24  Make_GONDA                             58776 non-null  category\n",
      " 25  Make_JIPU                              58776 non-null  category\n",
      " 26  Make_KIO                               58776 non-null  category\n",
      " 27  Make_LAMBOGI                           58776 non-null  category\n",
      " 28  Make_LAND CRAWLER                      58776 non-null  category\n",
      " 29  Make_LECUS                             58776 non-null  category\n",
      " 30  Make_MATSUDA                           58776 non-null  category\n",
      " 31  Make_MITSU                             58776 non-null  category\n",
      " 32  Make_NIRRAN                            58776 non-null  category\n",
      " 33  Make_RYUNDAI                           58776 non-null  category\n",
      " 34  Make_TOLVO                             58776 non-null  category\n",
      " 35  Make_TOYOTI                            58776 non-null  category\n",
      " 36  Fuel Type_D                            58776 non-null  category\n",
      " 37  Fuel Type_E                            58776 non-null  category\n",
      " 38  Fuel Type_N                            58776 non-null  category\n",
      " 39  Fuel Type_X                            58776 non-null  category\n",
      " 40  Fuel Type_Z                            58776 non-null  category\n",
      "dtypes: category(36), float64(5)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_test_to_model_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost\n",
    "- LGBM\n",
    "- DNN (NOT YET)\n",
    "- ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_xgb = XGBRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model_lgbm = lgb.LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# # Assuming you have training data X_train, y_train\n",
    "# model_dnn = Sequential()\n",
    "# model_dnn.add(\n",
    "#     Dense(256, input_dim=df_train_to_model_log.shape[1], activation=\"relu\")\n",
    "# )  # Input layer\n",
    "# model_dnn.add(Dense(256, activation=\"relu\"))  # Hidden layer 1\n",
    "# model_dnn.add(Dense(256, activation=\"relu\"))  # Hidden layer 2\n",
    "# model_dnn.add(Dense(1))  # Output layer\n",
    "\n",
    "# model_dnn.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "model_ensemble = StackingRegressor(estimators=[(\"xgb\", model_xgb), (\"lgbm\", model_lgbm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_boxcox_Fuel Consumption City (L/100Km)</th>\n",
       "      <th>T_boxcox_Fuel Consumption Hwy (L/100Km)</th>\n",
       "      <th>T_boxcox_Fuel Consumption Comb (L/100Km)</th>\n",
       "      <th>T_boxcox_Engine Size(L)</th>\n",
       "      <th>T_boxcox_Cylinders</th>\n",
       "      <th>Vehicle Class_0</th>\n",
       "      <th>Vehicle Class_1</th>\n",
       "      <th>Vehicle Class_2</th>\n",
       "      <th>Vehicle Class_3</th>\n",
       "      <th>Vehicle Class_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Make_MITSU</th>\n",
       "      <th>Make_NIRRAN</th>\n",
       "      <th>Make_RYUNDAI</th>\n",
       "      <th>Make_TOLVO</th>\n",
       "      <th>Make_TOYOTI</th>\n",
       "      <th>Fuel Type_D</th>\n",
       "      <th>Fuel Type_E</th>\n",
       "      <th>Fuel Type_N</th>\n",
       "      <th>Fuel Type_X</th>\n",
       "      <th>Fuel Type_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.244276</td>\n",
       "      <td>1.224908</td>\n",
       "      <td>3.947286</td>\n",
       "      <td>0.875550</td>\n",
       "      <td>0.517945</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.189469</td>\n",
       "      <td>4.587420</td>\n",
       "      <td>5.764516</td>\n",
       "      <td>0.881737</td>\n",
       "      <td>0.517858</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.705217</td>\n",
       "      <td>3.822731</td>\n",
       "      <td>5.768798</td>\n",
       "      <td>0.978827</td>\n",
       "      <td>0.524394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.460810</td>\n",
       "      <td>4.837306</td>\n",
       "      <td>5.461867</td>\n",
       "      <td>0.928319</td>\n",
       "      <td>0.521420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.830260</td>\n",
       "      <td>5.327378</td>\n",
       "      <td>7.781140</td>\n",
       "      <td>0.919186</td>\n",
       "      <td>0.523006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58771</th>\n",
       "      <td>5.734662</td>\n",
       "      <td>5.569789</td>\n",
       "      <td>6.010334</td>\n",
       "      <td>0.855433</td>\n",
       "      <td>0.516538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58772</th>\n",
       "      <td>3.022169</td>\n",
       "      <td>2.957070</td>\n",
       "      <td>3.105215</td>\n",
       "      <td>0.665022</td>\n",
       "      <td>0.505789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58773</th>\n",
       "      <td>5.026833</td>\n",
       "      <td>3.967286</td>\n",
       "      <td>4.765046</td>\n",
       "      <td>0.869114</td>\n",
       "      <td>0.517499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58774</th>\n",
       "      <td>3.658092</td>\n",
       "      <td>2.364939</td>\n",
       "      <td>3.205094</td>\n",
       "      <td>0.944922</td>\n",
       "      <td>0.523006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>5.990971</td>\n",
       "      <td>0.176043</td>\n",
       "      <td>4.339868</td>\n",
       "      <td>0.869114</td>\n",
       "      <td>0.517858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58776 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       T_boxcox_Fuel Consumption City (L/100Km)  \\\n",
       "0                                      5.244276   \n",
       "1                                      6.189469   \n",
       "2                                      6.705217   \n",
       "3                                      5.460810   \n",
       "4                                      8.830260   \n",
       "...                                         ...   \n",
       "58771                                  5.734662   \n",
       "58772                                  3.022169   \n",
       "58773                                  5.026833   \n",
       "58774                                  3.658092   \n",
       "58775                                  5.990971   \n",
       "\n",
       "       T_boxcox_Fuel Consumption Hwy (L/100Km)  \\\n",
       "0                                     1.224908   \n",
       "1                                     4.587420   \n",
       "2                                     3.822731   \n",
       "3                                     4.837306   \n",
       "4                                     5.327378   \n",
       "...                                        ...   \n",
       "58771                                 5.569789   \n",
       "58772                                 2.957070   \n",
       "58773                                 3.967286   \n",
       "58774                                 2.364939   \n",
       "58775                                 0.176043   \n",
       "\n",
       "       T_boxcox_Fuel Consumption Comb (L/100Km)  T_boxcox_Engine Size(L)  \\\n",
       "0                                      3.947286                 0.875550   \n",
       "1                                      5.764516                 0.881737   \n",
       "2                                      5.768798                 0.978827   \n",
       "3                                      5.461867                 0.928319   \n",
       "4                                      7.781140                 0.919186   \n",
       "...                                         ...                      ...   \n",
       "58771                                  6.010334                 0.855433   \n",
       "58772                                  3.105215                 0.665022   \n",
       "58773                                  4.765046                 0.869114   \n",
       "58774                                  3.205094                 0.944922   \n",
       "58775                                  4.339868                 0.869114   \n",
       "\n",
       "       T_boxcox_Cylinders Vehicle Class_0 Vehicle Class_1 Vehicle Class_2  \\\n",
       "0                0.517945               0               1               0   \n",
       "1                0.517858               0               1               1   \n",
       "2                0.524394               0               0               0   \n",
       "3                0.521420               0               1               0   \n",
       "4                0.523006               0               0               1   \n",
       "...                   ...             ...             ...             ...   \n",
       "58771            0.516538               0               0               0   \n",
       "58772            0.505789               0               0               0   \n",
       "58773            0.517499               0               0               1   \n",
       "58774            0.523006               0               0               0   \n",
       "58775            0.517858               0               0               0   \n",
       "\n",
       "      Vehicle Class_3 Vehicle Class_4  ... Make_MITSU Make_NIRRAN  \\\n",
       "0                   1               0  ...          0           0   \n",
       "1                   1               1  ...          0           0   \n",
       "2                   1               1  ...          1           0   \n",
       "3                   1               0  ...          0           0   \n",
       "4                   1               1  ...          0           0   \n",
       "...               ...             ...  ...        ...         ...   \n",
       "58771               1               1  ...          0           0   \n",
       "58772               0               1  ...          0           0   \n",
       "58773               1               1  ...          0           0   \n",
       "58774               0               1  ...          0           0   \n",
       "58775               1               1  ...          0           0   \n",
       "\n",
       "      Make_RYUNDAI Make_TOLVO Make_TOYOTI Fuel Type_D Fuel Type_E Fuel Type_N  \\\n",
       "0                0          0           0           0           0           0   \n",
       "1                0          0           0           0           0           0   \n",
       "2                0          0           0           0           0           0   \n",
       "3                0          0           0           0           0           0   \n",
       "4                0          0           0           0           0           0   \n",
       "...            ...        ...         ...         ...         ...         ...   \n",
       "58771            0          0           0           0           0           0   \n",
       "58772            0          0           0           0           0           0   \n",
       "58773            0          0           0           0           0           0   \n",
       "58774            0          0           0           0           0           0   \n",
       "58775            0          0           0           0           0           0   \n",
       "\n",
       "      Fuel Type_X Fuel Type_Z  \n",
       "0               1           0  \n",
       "1               1           0  \n",
       "2               1           0  \n",
       "3               0           1  \n",
       "4               0           1  \n",
       "...           ...         ...  \n",
       "58771           1           0  \n",
       "58772           1           0  \n",
       "58773           1           0  \n",
       "58774           1           0  \n",
       "58775           0           1  \n",
       "\n",
       "[58776 rows x 41 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_to_model_boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 1, Mean RMSE: 46.9422, Mean Training time: 0.8434 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 2, Mean RMSE: 46.9422, Mean Training time: 0.8722 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 3, Mean RMSE: 46.9206, Mean Training time: 0.5949 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: LGBMRegressor, Dataset: 4, Mean RMSE: 46.9414, Mean Training time: 0.8535 seconds\n",
      "Model: XGBRegressor, Dataset: 1, Mean RMSE: 46.5985, Mean Training time: 1.1841 seconds\n",
      "Model: XGBRegressor, Dataset: 2, Mean RMSE: 46.5669, Mean Training time: 0.9257 seconds\n",
      "Model: XGBRegressor, Dataset: 3, Mean RMSE: 46.5669, Mean Training time: 1.0085 seconds\n",
      "Model: XGBRegressor, Dataset: 4, Mean RMSE: 46.6655, Mean Training time: 1.0201 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 1, Mean RMSE: 46.2681, Mean Training time: 9.8661 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 2, Mean RMSE: 46.2498, Mean Training time: 10.6001 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1092\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 3, Mean RMSE: 46.2400, Mean Training time: 10.3003 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.320278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1082\n",
      "[LightGBM] [Info] Number of data points in the train set: 87769, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.523015\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.294956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.437891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.240174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.547946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442285\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.442405\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.585083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.387368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.636895\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.359131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.614508\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.674031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.476316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.635883\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.358119\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.638738\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.648788\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.475303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.459565\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.181801\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 87770, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 250.462420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.409438\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 87771, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.538338\n",
      "Model: StackingRegressor, Dataset: 4, Mean RMSE: 46.2983, Mean Training time: 9.4043 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'models' is a list of your models\n",
    "models = [model_lgbm, model_xgb, model_ensemble]\n",
    "\n",
    "# Create a list of your datasets\n",
    "datasets = [\n",
    "    df_train_to_model_log,\n",
    "    df_train_to_model_sqrt,\n",
    "    df_train_to_model_boxcox,\n",
    "    df_train_to_model_inverse,\n",
    "]\n",
    "\n",
    "y = df_target\n",
    "\n",
    "# Initialize a dictionary to hold your results\n",
    "results = {}\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Loop over your models\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    results[model_name] = {}\n",
    "\n",
    "    # Loop over your datasets\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        results[model_name][f\"dataset_{i+1}\"] = {\n",
    "            \"rmse\": [],\n",
    "            \"training_time\": [],\n",
    "        }\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, test_index in kf.split(dataset):\n",
    "            X_train, X_test = dataset.iloc[train_index], dataset.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "            # Create a StandardScaler object\n",
    "            # scaler = StandardScaler()\n",
    "            scaler = MinMaxScaler()\n",
    "\n",
    "            numerical_column = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "            non_numerical_columns = [\n",
    "                col for col in X_train.columns if col not in numerical_column\n",
    "            ]\n",
    "            for col in non_numerical_columns:\n",
    "                X_train.loc[:, col] = X_train.loc[:, col].astype(\"int64\")\n",
    "                X_test.loc[:, col] = X_test.loc[:, col].astype(\"int64\")\n",
    "\n",
    "            # Normalize the data\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # Start the timer\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # End the timer\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Calculate the training time\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            # Store the results\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"].append(rmse)\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"].append(training_time)\n",
    "\n",
    "        # Calculate the mean RMSE and training time\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"rmse\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"rmse\"]\n",
    "        )\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"training_time\"] = np.mean(\n",
    "            results[model_name][f\"dataset_{i+1}\"][\"training_time\"]\n",
    "        )\n",
    "\n",
    "        # Print the process\n",
    "        print(\n",
    "            f\"Model: {model_name}, Dataset: {i+1}, Mean RMSE: {results[model_name][f'dataset_{i+1}']['rmse']:.4f}, Mean Training time: {results[model_name][f'dataset_{i+1}']['training_time']:.4f} seconds\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.239974</td>\n",
       "      <td>10.300298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.249831</td>\n",
       "      <td>10.600114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.268106</td>\n",
       "      <td>9.866058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.298292</td>\n",
       "      <td>9.404344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.566862</td>\n",
       "      <td>0.925737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.566862</td>\n",
       "      <td>1.008521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.598451</td>\n",
       "      <td>1.184074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.665463</td>\n",
       "      <td>1.020070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>46.920581</td>\n",
       "      <td>0.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>46.941424</td>\n",
       "      <td>0.853548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>46.942169</td>\n",
       "      <td>0.843362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>46.942169</td>\n",
       "      <td>0.872237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model    Dataset       RMSE  Training Time\n",
       "10  StackingRegressor  dataset_3  46.239974      10.300298\n",
       "9   StackingRegressor  dataset_2  46.249831      10.600114\n",
       "8   StackingRegressor  dataset_1  46.268106       9.866058\n",
       "11  StackingRegressor  dataset_4  46.298292       9.404344\n",
       "5        XGBRegressor  dataset_2  46.566862       0.925737\n",
       "6        XGBRegressor  dataset_3  46.566862       1.008521\n",
       "4        XGBRegressor  dataset_1  46.598451       1.184074\n",
       "7        XGBRegressor  dataset_4  46.665463       1.020070\n",
       "2       LGBMRegressor  dataset_3  46.920581       0.594900\n",
       "3       LGBMRegressor  dataset_4  46.941424       0.853548\n",
       "0       LGBMRegressor  dataset_1  46.942169       0.843362\n",
       "1       LGBMRegressor  dataset_2  46.942169       0.872237"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the nested dictionary into a pandas DataFrame\n",
    "df_results = pd.concat({k: pd.DataFrame(v).T for k, v in results.items()}, axis=0)\n",
    "\n",
    "# Reset the index and rename the columns for a cleaner look\n",
    "df_results.reset_index(inplace=True)\n",
    "df_results.columns = [\"Model\", \"Dataset\", \"RMSE\", \"Training Time\"]\n",
    "\n",
    "df_results.to_csv(\"results_to_submit.csv\")\n",
    "df_sorted = df_results.sort_values(by=\"RMSE\", ascending=True)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "Model: LGBMRegressor, Dataset: 1, Training time: 0.9939 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "Model: LGBMRegressor, Dataset: 2, Training time: 0.7490 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "Model: LGBMRegressor, Dataset: 3, Training time: 1.0997 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "Model: LGBMRegressor, Dataset: 4, Training time: 1.3644 seconds\n",
      "Model: XGBRegressor, Dataset: 1, Training time: 1.7430 seconds\n",
      "Model: XGBRegressor, Dataset: 2, Training time: 1.9331 seconds\n",
      "Model: XGBRegressor, Dataset: 3, Training time: 1.8961 seconds\n",
      "Model: XGBRegressor, Dataset: 4, Training time: 1.9545 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: StackingRegressor, Dataset: 1, Training time: 12.7615 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: StackingRegressor, Dataset: 2, Training time: 10.8470 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1095\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1094\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: StackingRegressor, Dataset: 3, Training time: 10.3711 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 137141, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.471627\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109712, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.363262\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.481018\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.552176\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.551366\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 109713, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 250.410313\n",
      "Model: StackingRegressor, Dataset: 4, Training time: 9.5186 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'models' is a list of your models\n",
    "models = [model_lgbm, model_xgb, model_ensemble]\n",
    "\n",
    "# Create a list of your train datasets\n",
    "train_datasets = [\n",
    "    df_train_to_model_log,\n",
    "    df_train_to_model_sqrt,\n",
    "    df_train_to_model_boxcox,\n",
    "    df_train_to_model_inverse,\n",
    "]\n",
    "\n",
    "# Create a list of your test datasets\n",
    "test_datasets = [\n",
    "    df_test_to_model_log,\n",
    "    df_test_to_model_sqrt,\n",
    "    df_test_to_model_boxcox,\n",
    "    df_test_to_model_inverse,\n",
    "]\n",
    "\n",
    "y = df_target\n",
    "\n",
    "# Initialize a dictionary to hold your results\n",
    "results = {}\n",
    "\n",
    "# Loop over your models\n",
    "for model in models:\n",
    "    model_name = type(model).__name__\n",
    "    results[model_name] = {}\n",
    "\n",
    "    # Loop over your datasets\n",
    "    for i, (train_dataset, test_dataset) in enumerate(\n",
    "        zip(train_datasets, test_datasets)\n",
    "    ):\n",
    "        results[model_name][f\"dataset_{i+1}\"] = {\n",
    "            \"predictions\": [],\n",
    "            \"training_time\": [],\n",
    "        }\n",
    "\n",
    "        X_train = train_dataset\n",
    "        y_train = y\n",
    "\n",
    "        # Create a MinMaxScaler object\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        numerical_column = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "        non_numerical_columns = [\n",
    "            col for col in X_train.columns if col not in numerical_column\n",
    "        ]\n",
    "        for col in non_numerical_columns:\n",
    "            X_train.loc[:, col] = X_train.loc[:, col].astype(\"int64\")\n",
    "\n",
    "        # Normalize the train data\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Start the timer\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # End the timer\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate the training time\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        # Normalize the test data\n",
    "        X_test = test_dataset\n",
    "        for col in non_numerical_columns:\n",
    "            X_test.loc[:, col] = X_test.loc[:, col].astype(\"int64\")\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Store the results\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"predictions\"] = predictions\n",
    "        results[model_name][f\"dataset_{i+1}\"][\"training_time\"] = training_time\n",
    "\n",
    "        # Print the process\n",
    "        print(\n",
    "            f\"Model: {model_name}, Dataset: {i+1}, Training time: {results[model_name][f'dataset_{i+1}']['training_time']:.4f} seconds\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>predictions</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>[257.4333843577355, 391.2711779732619, 235.414...</td>\n",
       "      <td>0.993876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>[257.4333843577355, 391.2711779732619, 235.414...</td>\n",
       "      <td>0.748997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>[240.04145429792575, 373.92650560779424, 333.4...</td>\n",
       "      <td>1.099655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>[255.3775955289704, 390.4991780239178, 236.479...</td>\n",
       "      <td>1.364389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>[253.64839, 397.09702, 247.60767, 309.2603, 36...</td>\n",
       "      <td>1.742997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>[253.64839, 397.09702, 247.60767, 309.2603, 36...</td>\n",
       "      <td>1.933057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>[173.94583, 304.45428, 243.39618, 321.24396, 4...</td>\n",
       "      <td>1.896135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>[257.9846, 396.9588, 218.35283, 310.51492, 358...</td>\n",
       "      <td>1.954471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>[255.44774377629415, 399.7096292400326, 242.08...</td>\n",
       "      <td>12.761528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_2</td>\n",
       "      <td>[255.44783628527404, 399.73423370733474, 242.0...</td>\n",
       "      <td>10.846962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_3</td>\n",
       "      <td>[200.9884146132802, 337.69175783942717, 283.71...</td>\n",
       "      <td>10.371060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StackingRegressor</td>\n",
       "      <td>dataset_4</td>\n",
       "      <td>[257.04508243166697, 399.33628404358075, 225.6...</td>\n",
       "      <td>9.518560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name dataset_name  \\\n",
       "0       LGBMRegressor    dataset_1   \n",
       "1       LGBMRegressor    dataset_2   \n",
       "2       LGBMRegressor    dataset_3   \n",
       "3       LGBMRegressor    dataset_4   \n",
       "4        XGBRegressor    dataset_1   \n",
       "5        XGBRegressor    dataset_2   \n",
       "6        XGBRegressor    dataset_3   \n",
       "7        XGBRegressor    dataset_4   \n",
       "8   StackingRegressor    dataset_1   \n",
       "9   StackingRegressor    dataset_2   \n",
       "10  StackingRegressor    dataset_3   \n",
       "11  StackingRegressor    dataset_4   \n",
       "\n",
       "                                          predictions  training_time  \n",
       "0   [257.4333843577355, 391.2711779732619, 235.414...       0.993876  \n",
       "1   [257.4333843577355, 391.2711779732619, 235.414...       0.748997  \n",
       "2   [240.04145429792575, 373.92650560779424, 333.4...       1.099655  \n",
       "3   [255.3775955289704, 390.4991780239178, 236.479...       1.364389  \n",
       "4   [253.64839, 397.09702, 247.60767, 309.2603, 36...       1.742997  \n",
       "5   [253.64839, 397.09702, 247.60767, 309.2603, 36...       1.933057  \n",
       "6   [173.94583, 304.45428, 243.39618, 321.24396, 4...       1.896135  \n",
       "7   [257.9846, 396.9588, 218.35283, 310.51492, 358...       1.954471  \n",
       "8   [255.44774377629415, 399.7096292400326, 242.08...      12.761528  \n",
       "9   [255.44783628527404, 399.73423370733474, 242.0...      10.846962  \n",
       "10  [200.9884146132802, 337.69175783942717, 283.71...      10.371060  \n",
       "11  [257.04508243166697, 399.33628404358075, 225.6...       9.518560  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the results dictionary\n",
    "flat_results = []\n",
    "for model_name, datasets in results.items():\n",
    "    for dataset_name, metrics in datasets.items():\n",
    "        flat_results.append(\n",
    "            {\n",
    "                \"model_name\": model_name,\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"predictions\": metrics[\"predictions\"],\n",
    "                \"training_time\": metrics[\"training_time\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert the flattened results to a DataFrame\n",
    "df_results_submit = pd.DataFrame(flat_results)\n",
    "df_results_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200.98841461, 337.69175784, 283.71207647, ..., 236.42852584,\n",
       "       277.49618488, 223.50738832])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_regressor_predictions = results[\"StackingRegressor\"][\"dataset_3\"][\n",
    "    \"predictions\"\n",
    "]\n",
    "stacking_regressor_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv(\"./dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CO2 Emissions(g/km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137142</td>\n",
       "      <td>200.988415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137143</td>\n",
       "      <td>337.691758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137144</td>\n",
       "      <td>283.712076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137145</td>\n",
       "      <td>310.094764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137146</td>\n",
       "      <td>390.320249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58771</th>\n",
       "      <td>195913</td>\n",
       "      <td>249.387491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58772</th>\n",
       "      <td>195914</td>\n",
       "      <td>253.341301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58773</th>\n",
       "      <td>195915</td>\n",
       "      <td>236.428526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58774</th>\n",
       "      <td>195916</td>\n",
       "      <td>277.496185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>195917</td>\n",
       "      <td>223.507388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  CO2 Emissions(g/km)\n",
       "0      137142           200.988415\n",
       "1      137143           337.691758\n",
       "2      137144           283.712076\n",
       "3      137145           310.094764\n",
       "4      137146           390.320249\n",
       "...       ...                  ...\n",
       "58771  195913           249.387491\n",
       "58772  195914           253.341301\n",
       "58773  195915           236.428526\n",
       "58774  195916           277.496185\n",
       "58775  195917           223.507388\n",
       "\n",
       "[58776 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission[\"CO2 Emissions(g/km)\"] = stacking_regressor_predictions\n",
    "df_sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission.to_csv(\"stack_regressor.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv31011",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
